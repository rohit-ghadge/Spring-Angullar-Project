<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>MIR: A lightweight JIT compiler project</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PDvpKffeLA8/" /><category term="C" /><category term="clang/LLVM" /><category term="Performance" /><category term="Ruby" /><category term="CRuby" /><category term="JIT compiler" /><category term="MIR" /><category term="optimization" /><author><name>Vladimir Makarov</name></author><id>https://developers.redhat.com/blog/?p=664687</id><updated>2020-01-20T08:00:32Z</updated><published>2020-01-20T08:00:32Z</published><content type="html">&lt;p&gt;For the past three years, I&amp;#8217;ve been participating in adding just-in-time compilation (&lt;a href="https://en.wikipedia.org/wiki/Just-in-time_compilation" target="_blank" rel="noopener noreferrer"&gt;JIT&lt;/a&gt;) to &lt;a href="https://github.com/ruby/ruby" target="_blank" rel="noopener noreferrer"&gt;CRuby&lt;/a&gt;. Now, CRuby has the &lt;a href="https://www.rubyguides.com/2018/11/ruby-mjit/"&gt;method-based just-in-time compiler (MJIT)&lt;/a&gt;, which improves performance for non-input/output-bound programs.&lt;/p&gt; &lt;p&gt;The most popular approach to implementing a JIT is to use &lt;a href="https://llvm.org" target="_blank" rel="noopener noreferrer"&gt;LLVM&lt;/a&gt; or &lt;a href="https://gcc.gnu.org/" target="_blank" rel="noopener noreferrer"&gt;GCC&lt;/a&gt; JIT interfaces, like &lt;a href="https://llvm.org/docs/ORCv2.html" target="_blank" rel="noopener noreferrer"&gt;ORC&lt;/a&gt; or &lt;a href="https://gcc.gnu.org/onlinedocs/jit/" target="_blank" rel="noopener noreferrer"&gt;LibGCCJIT&lt;/a&gt;. GCC and LLVM developers spend huge effort to implement the optimizations reliably, effectively, and to work on a lot of targets. Using LLVM or GCC to implement JIT, we can just utilize these optimizations for free. Using the existing compilers was the only way to get JIT for CRuby in the short time before the Ruby 3.0 release, which has the goal of &lt;a href="https://blog.heroku.com/ruby-3-by-3" target="_blank" rel="noopener noreferrer"&gt;improving CRuby performance by three times&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;So, CRuby MJIT utilizes GCC or LLVM, but what is unique about this JIT?&lt;span id="more-664687"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;MJIT does not use existing compiler JIT interfaces. Instead, it uses C as an interface language without losing compilation speed. Practically the same compilation speed as with the existing JIT interfaces is achieved by using &lt;a href="https://en.wikipedia.org/wiki/Precompiled_header" target="_blank" rel="noopener noreferrer"&gt;precompiled headers&lt;/a&gt; and a memory filesystem.&lt;/p&gt; &lt;p&gt;Choosing C as a JIT interface language significantly simplifies JIT implementation, maintenance, and debugging. Doing so also makes the JIT independent from a particular C compiler. Precompiled headers are a pretty standard feature of modern C/C++ compilers.&lt;/p&gt; &lt;h2 id="disadvantages-of-gccllvm-based-jit"&gt;Disadvantages of GCC/LLVM-based JIT&lt;/h2&gt; &lt;p&gt;Enough about the advantages of GCC/LLVM-based JITs. Let us speak about the disadvantages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;GCC/LLVM-based JITs are big.&lt;/li&gt; &lt;li&gt;Their compilation speed can be slow.&lt;/li&gt; &lt;li&gt;It is hard to implement combined optimizations of code written in different programming languages.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Regarding the last point, in the case of CRuby, Ruby and C must be optimized together as you can be using implementation languages of different Ruby methods. Let us consider these disadvantages in more detail.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;GCC/LLVM size&lt;/h3&gt; &lt;p&gt;First of all, GCC and LLVM are big compared to CRuby. How big? If we ask &lt;a href="https://dwheeler.com/sloccount" target="_blank" rel="noopener noreferrer"&gt;SLOCCount&lt;/a&gt;, GCC and LLVM sources are about three times larger than CRuby, as shown in Figure 1. CRuby is already a big project by itself, with its source consisting of more than 1.5 million lines of code:&lt;/p&gt; &lt;div id="attachment_664837" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664837" class="wp-image-664837 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-1024x505.png" alt="The relative source code sizes of GCC, CRuby, and the LLVM option." width="640" height="316" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-1024x505.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-300x148.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide-768x379.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/sloc-wide.png 1467w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664837" class="wp-caption-text"&gt;Figure 1: CRuby’s source code size compared to GCC&amp;#8217;s and LLVM&amp;#8217;s source code size.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As for the machine code, GCC and LLVM binaries are much bigger, from 7 to 18 times bigger, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_664817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664817" class="wp-image-664817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-1024x566.png" alt="The relative machine code sizes of GCC, CRuby, and LLVM." width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-1024x566.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide-768x425.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/objsize-wide.png 1307w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664817" class="wp-caption-text"&gt;Figure 2: CRuby’s machine code is significantly smaller than GCC&amp;#8217;s and LLVM&amp;#8217;s machine code.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Imagine adding a JIT for a simple language with LLVM. You can easily increase its interpreter binary code size by a hundred times. CRuby with the current JIT requires much less memory than &lt;a href="https://www.jruby.org" target="_blank" rel="noopener noreferrer"&gt;JRuby&lt;/a&gt; or &lt;a href="https://github.com/oracle/truffleruby" target="_blank" rel="noopener noreferrer"&gt;Graal/TruffleRuby&lt;/a&gt;. Still, the large code size can be a serious problem for cloud, &lt;a href="https://en.wikipedia.org/wiki/Internet_of_things" target="_blank" rel="noopener noreferrer"&gt;IoT&lt;/a&gt;, or mobile environments.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;GCC/LLVM compilation speed&lt;/h3&gt; &lt;p&gt;Second, GCC/LLVM compilation speed is slow. It might feel like 20ms on a modern Intel CPU for a method compilation with GCC/LLVM is short, but for less powerful but widely used CPUs this value can be a half-second. For example, according to the &lt;a href="https://www.spec.org/cpu2000/CINT2000/176.gcc/docs/176.gcc.html" target="_blank" rel="noopener noreferrer"&gt;SPEC2000 176.gcc&lt;/a&gt; benchmark, the &lt;a href="https://en.wikipedia.org/wiki/Raspberry_Pi" target="_blank" rel="noopener noreferrer"&gt;Raspberry PI3 B3+&lt;/a&gt; CPU is about 30 times slower than the Intel i7-9700K (score 320 vs. 8520).&lt;/p&gt; &lt;p&gt;We need JIT even more on slow machines, but JIT compilation becomes intolerably slow for these. Even on fast machines, GCC/LLVM-based JITs can be too slow in environments like &lt;a href="https://en.wikipedia.org/wiki/MinGW" target="_blank" rel="noopener noreferrer"&gt;MinGW&lt;/a&gt;. Faster JIT speed can also help achieve desirable JIT performance through aggressive &lt;a href="https://en.wikipedia.org/wiki/Adaptive_optimization" target="_blank" rel="noopener noreferrer"&gt;adaptive optimization&lt;/a&gt; and &lt;a href="https://compileroptimizations.com/category/function_inlining.htm" target="_blank" rel="noopener noreferrer"&gt;function inlining&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What might a faster JIT compilation look like? A keynote about the &lt;a href="https://youtu.be/Uqch1rjPls8" target="_blank" rel="noopener noreferrer"&gt;Java Falcon compiler&lt;/a&gt; at the 2017 LLVM developers conference suggested about 100ms per method for an LLVM-based JIT compiler and one millisecond for the faster &lt;a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html#tieredcompilation" target="_blank" rel="noopener noreferrer"&gt;tier-one JVM compiler&lt;/a&gt;. Answering a question about using LLVM for a Python JIT implementation, the speaker (Philip Reems) said that you first need a tier-one compiler implementation. With MJIT for Ruby, we went from the opposite direction by implementing a tier two compiler first.&lt;/p&gt; &lt;p&gt;So, why is GCC/LLVM compilation slow? Here is a full list of GCC-8 backend passes presented in their execution order, as shown in Figure 3:&lt;/p&gt; &lt;div id="attachment_664987" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664987" class="wp-image-664987 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-1024x768.png" alt="" width="640" height="480" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-1024x768.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/passes-1-768x576.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-664987" class="wp-caption-text"&gt;Figure 3: GCC-8 backend passes presented in their execution order.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;There are 321 compiler passes and 239 of them are unique. This fact probably reflects that the GCC community has had more than 600 contributors. Some of these passes are repeated runs of the same optimizations (e.g., &lt;a href="https://en.wikipedia.org/wiki/Dead_code_elimination" target="_blank" rel="noopener noreferrer"&gt;dead code elimination&lt;/a&gt;). Many compiler passes traverse the &lt;a href="https://en.wikipedia.org/wiki/Intermediate_representation" target="_blank" rel="noopener noreferrer"&gt;intermediate representation&lt;/a&gt; (IR) more than once. For example, the &lt;a href="https://en.wikipedia.org/wiki/Register_allocation" target="_blank" rel="noopener noreferrer"&gt;register allocator&lt;/a&gt; traverses it at least eight times. Running all of these passes requires a lot of time. There are those who think that by switching off most of the passes we can speed up GCC/LLVM compilation proportionally. Unfortunately, this is not true.&lt;/p&gt; &lt;p&gt;The biggest problem for using GCC and LLVM in a lightweight JIT compiler is long initialization time. For small code, initialization can take a majority of the compilation time, and small-method code is a typical scenario for Ruby and other programs in other &lt;a href="https://en.wikipedia.org/wiki/Dynamic_programming_language" target="_blank" rel="noopener noreferrer"&gt;dynamic&lt;/a&gt; high-level languages.&lt;/p&gt; &lt;p&gt;The following diagram illustrates the long startup time of GCC-8/LLVM-8 on an Intel i7-9700K under &lt;a href="https://start.fedoraproject.org" target="_blank" rel="noopener noreferrer"&gt;Fedora Core&lt;/a&gt; 29, as shown in Figure 4:&lt;/p&gt; &lt;div id="attachment_664897" style="width: 625px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664897" class="wp-image-664897 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup.png" alt="GCC-8/LLVM-8 takes a long time to start up on an Intel i7-9700K under Fedora Core 29." width="615" height="460" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup.png 615w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/startup-300x224.png 300w" sizes="(max-width: 615px) 100vw, 615px" /&gt;&lt;p id="caption-attachment-664897" class="wp-caption-text"&gt;Figure 4: GCC-8/LLVM-8 startup time on an Intel i7-9700K under Fedora Core 29.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;So, you can not switch off optimizations and proportionally speed up GCC and Clang.&lt;/p&gt; &lt;h3 id="disadvantages-of-gccllvm-based-jit"&gt;Function inlining with GCC/LLVM&lt;/h3&gt; &lt;p&gt;Function inlining is the most important optimization for better JIT performance. Method calls are expensive and inlining permits optimizations in a bigger scope.&lt;/p&gt; &lt;p&gt;When both are written in Ruby, inlining one method into another one is a not a problem. We can do this on the VM instruction level or when we generate machine code. The problem is inlining a method written on C into a method written on Ruby or vice versa.&lt;/p&gt; &lt;p&gt;Here is a small example:&lt;/p&gt; &lt;pre&gt; x = 2 10.times {x *= 2}&lt;/pre&gt; &lt;p&gt;Ruby code interpreted by the CRuby &lt;a href="https://en.wikipedia.org/wiki/Virtual_machine" target="_blank" rel="noopener noreferrer"&gt;VM&lt;/a&gt; calls the method &lt;code&gt;times&lt;/code&gt;, which is implemented in C. This C code repeatedly calls another Ruby method interpreted by the VM and implementing a multiplication operation, as shown in Figure 5:&lt;/p&gt; &lt;div id="attachment_664907" style="width: 590px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664907" class="wp-image-664907 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/times.png" alt="How the times method works with CRuby." width="580" height="170" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/times.png 580w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/times-300x88.png 300w" sizes="(max-width: 580px) 100vw, 580px" /&gt;&lt;p id="caption-attachment-664907" class="wp-caption-text"&gt;Figure 5: The &lt;code&gt;times&lt;/code&gt; method through CRuby.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;How can we integrate all three parts of the code into one generated function? Let us consider the current structure of MJIT, as shown in Figure 6:&lt;/p&gt; &lt;div id="attachment_664887" style="width: 638px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664887" class="wp-image-664887 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header.png" alt="MJIT's structure." width="628" height="335" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header.png 628w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT-header-300x160.png 300w" sizes="(max-width: 628px) 100vw, 628px" /&gt;&lt;p id="caption-attachment-664887" class="wp-caption-text"&gt;Figure 6: MJIT&amp;#8217;s structure.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;A C function that implements a standard Ruby method and can be inlined should be in the precompiled header. The more code we insert into the environment header, the slower the MJIT precompiled header generation, and thus the slower the MJIT startup. Another consequence is slower JIT code generation because of bigger precompiled header.&lt;/p&gt; &lt;p&gt;We could also rewrite C code in Ruby. Sometimes this could work, but in the majority of cases, doing so would result in slower generated code.&lt;/p&gt; &lt;h2 id="light-weight-jit-compiler"&gt;Lightweight JIT compiler&lt;/h2&gt; &lt;p&gt;After analyzing the current disadvantages of MJIT, I came to the conclusion that a lightweight JIT compiler could solve these issues. I think the lightweight JIT compiler should be either an addition to the existing MJIT compiler or the only JIT compiler in cases where the current one does not work.&lt;/p&gt; &lt;p&gt;There is another reason for the lightweight JIT compiler. I believe this compiler could be a good solution for MRuby JIT and would help to expand Ruby usage from a mostly server market to the mobile and IoT markets.&lt;/p&gt; &lt;p&gt;So, last year I started to work on a lightweight JIT compiler mostly in my spare time. Because I&amp;#8217;d like to use the JIT compiler not only for Ruby, I decided to make it a universal JIT compiler and a standalone project.&lt;/p&gt; &lt;h2&gt;MIR&lt;/h2&gt; &lt;p&gt;The central notion of JIT is a well-defined intermediate language called Medium Internal Representation, or MIR. You can find the name in &lt;a href="https://www.amazon.ca/Advanced-Compiler-Design-Implementation-Muchnick/dp/1558603204" target="_blank" rel="noopener noreferrer"&gt;Steven Muchnik&amp;#8217;s famous book &amp;#8220;Advanced Compiler Design and Implementation.&amp;#8221;&lt;/a&gt; The &lt;a href="https://www.rust-lang.org/" target="_blank" rel="noopener noreferrer"&gt;Rust&lt;/a&gt; team also uses this term for a Rust intermediate language. Still, I decided to use the same name because I like it: MIR means &amp;#8220;peace&amp;#8221; and &amp;#8220;world&amp;#8221; in Russian.&lt;/p&gt; &lt;p&gt;MIR is strongly typed and flexible enough. MIR in different forms is capable of representing machine code for both &lt;a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer" target="_blank" rel="noopener noreferrer"&gt;CISC&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer" target="_blank" rel="noopener noreferrer"&gt;RISC&lt;/a&gt; processors. Although this lightweight JIT compiler is a standalone project, I am planning to try it first with CRuby or MRuby JIT.&lt;/p&gt; &lt;p&gt;To get a better understanding of MIR, let us consider the Eratosthenes prime sieve algorithm code as an example. Here is the C code for sieve:&lt;/p&gt; &lt;pre&gt;#define Size 819000 int sieve (int iter) { int i, k, prime, count, n; char flags[Size]; for (n = 0; n &amp;#60; iter; n++) { count = 0; for (i = 0; i &amp;#60; Size; i++) flags[i] = 1; for (i = 0; i &amp;#60; Size; i++) if (flags[i]) { prime = i + i + 3; for (k = i + prime; k &amp;#60; Size; k += prime) flags[k] = 0; count++; } } return count; }&lt;/pre&gt; &lt;p&gt;And here is the MIR textual representation for the same code. There are no hard registers in MIR, only typed variables. The &lt;a href="https://en.wikipedia.org/wiki/Calling_convention" target="_blank" rel="noopener noreferrer"&gt;calling convention&lt;/a&gt; is also hidden:&lt;/p&gt; &lt;pre&gt;m_sieve: module export sieve sieve: func i32, i32:iter local i64:flags, i64:count, i64:prime, i64:n, i64:i, i64:k, i64:temp alloca flags, 819000 mov n, 0 loop: bge fin, n, iter mov count, 0; mov i, 0 loop2: bgt fin2, i, 819000 mov ui8:(flags, i), 1; add i, i, 1 jmp loop2 fin2: mov i, 0 loop3: bgt fin3, i, 819000 beq cont3, ui8:(flags,i), 0 add temp, i, i; add prime, temp, 3; add k, i, prime loop4: bgt fin4, k, 819000 mov ui8:(flags, k), 0; add k, k, prime jmp loop4 fin4: add count, count, 1 cont3: add i, i, 1 jmp loop3 fin3: add n, n, 1; jmp loop fin: ret count endfunc endmodule&lt;/pre&gt; &lt;p&gt;The first operands in the &lt;code&gt;func&lt;/code&gt; pseudo-instruction are the function return types (a MIR function can return multiple values), and after that, all function arguments are declared. Local variables are declared as 64-bit integers through the &lt;em&gt;local&lt;/em&gt; pseudo-instruction.&lt;/p&gt; &lt;h2 id="light-weight-jit-compiler-project-goals"&gt;Lightweight JIT compiler project goals&lt;/h2&gt; &lt;p&gt;I set performance goals for the JIT compiler. Compared to GCC with -O2, this compiler should have 100 times faster compilation, 100 times faster start-up, and 100 times smaller code size. As for the generated code performance, I decided that it should be at least 70% of GCC -O2 performance.&lt;/p&gt; &lt;p&gt;The implementation should be simple too at less than 10K C lines, because I want wider adoption of this tool. Simple code is easier to learn and maintain. I&amp;#8217;d like also to avoid any external dependencies for this project. At the end of the article, you can see the actual results I have now.&lt;/p&gt; &lt;h3 id="how-to-achieve-the-performance-goals"&gt;How to achieve these performance goals&lt;/h3&gt; &lt;p&gt;Optimizing compilers are big and complex because they are trying to improve any code, including rare edge cases. Because they do a lot of things, compilation speed becomes important. These compilers use the fastest algorithms and data structures for compiled programs of different sizes, from small to huge ones, even if the algorithms and data structures are complicated.&lt;/p&gt; &lt;p&gt;So, to achieve our goals, we need to use a few of the most valuable optimizations, optimize only frequently occurring cases, and use algorithms with the best combination of simplicity and performance.&lt;/p&gt; &lt;p&gt;So what are the most valuable optimizations? The most important optimizations are those for effectively exploiting the most commonly used CPU resources: instructions and registers. Therefore, the most valuable optimizations are good register allocation (RA) and &lt;a href="https://en.wikipedia.org/wiki/Instruction_selection" target="_blank" rel="noopener noreferrer"&gt;instruction selection&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Recently, I did an experiment by switching on only a fast and simple RA and combiner in GCC. There are no options to do this, I needed to modify GCC. (I can provide a patch if somebody is interested.) Compared to hundreds of optimizations in GCC-9.0 with -O2, these two optimizations achieve almost 80% performance on an Intel i7-9700K machine under Fedora Core 29 for real-world programs through &lt;a href="https://www.spec.org/benchmarks.html#cpu" target="_blank" rel="noopener noreferrer"&gt;SpecCPU&lt;/a&gt;, one of the most credible compiler benchmark suites:&lt;/p&gt; &lt;table style="height: 90px;" width="608" align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;SPECInt2000 Est.&lt;/th&gt; &lt;th&gt;GCC -O2&lt;/th&gt; &lt;th&gt;GCC -O0 + simple RA + combiner&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;-fno-inline&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;5458&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4342 (80%)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;-finline&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;6141&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4339 (71%)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;You might ask, &amp;#8220;How is this possible? What do the other numerous optimizations do?&amp;#8221; Having worked for many years on optimizing compilers, I would like to take this opportunity to say how difficult it is to improve the performance of well-established optimizing compilers.&lt;/p&gt; &lt;h3 id="how-to-achieve-the-performance-goals"&gt;The reality of optimizing compiler performance&lt;/h3&gt; &lt;p&gt;In the integrated circuit world, there is &lt;a href="https://en.wikipedia.org/wiki/Moore%27s_law" target="_blank" rel="noopener noreferrer"&gt;Moore&amp;#8217;s law&lt;/a&gt;, which says that the number of transistors on the circuit doubles every 18 months.&lt;/p&gt; &lt;p&gt;In the optimizing compiler world, people like to mention &lt;a href="http://proebsting.cs.arizona.edu/law.html" target="_blank" rel="noopener noreferrer"&gt;Proebsting&amp;#8217;s law&lt;/a&gt; to show how hard it is to improve the performance of generated code. Proebsting&amp;#8217;s law says that optimizing compiler developers improve generated code performance by two times every 18 years.&lt;/p&gt; &lt;p&gt;Actually, this &amp;#8220;law&amp;#8221; is too optimistic, and I never saw that anyone tested this. (It is hard to check because you need to wait 18 years.) So, recently I checked it on SPEC CPU2000. SPEC CPU is one of the most credible benchmark suites used by optimizing compiler developers. It contains a set of CPU-intensive applications from the real world; for example, a specific version of GCC is one of the benchmarks. There are many versions of SPEC CPU: 2000, 2006, and 2017. I used the 2000 version because it does not require days to run it. I used the 17-year-old GCC-3.1 compiler (the first GCC version supporting AMD64) and the recent version GCC-8 in their peak performance modes on the same Intel i7-4790K processor:&lt;/p&gt; &lt;table style="height: 59px;" width="608" align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;GCC 3.1 (-O3)&lt;/th&gt; &lt;th&gt;GCC 8 (-Ofast -flto -march=native)&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;SPECInt2000 w/o eon&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;4498&lt;/td&gt; &lt;td style="padding-left: 40px;"&gt;5212 (+16%)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The actual performance improvement is &lt;strong&gt;only 16%&lt;/strong&gt;, which is not close to the 100% Proebsting&amp;#8217;s law states.&lt;/p&gt; &lt;p&gt;Looking at the progress of optimizing compilers, people believe we should not spend our time on their development at all. Dr. Bernstein, an author of the &lt;a href="https://en.wikipedia.org/wiki/SipHash" target="_blank" rel="noopener noreferrer"&gt;SipHash&lt;/a&gt; algorithm used in CRuby, expressed this point of view in &lt;a href="https://cr.yp.to/talks/2015.04.16/slides-djb-20150416-a4.pdf" target="_blank" rel="noopener noreferrer"&gt;one of his talks&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;There is another point of view that we should still try to improve the performance of generated code. &lt;a href="https://www.theregister.co.uk/2013/08/16/it_electricity_use_worse_than_you_thought" target="_blank" rel="noopener noreferrer"&gt;By some estimates&lt;/a&gt;, in 2013 (before active cryptocurrency mining) computers consumed 10% of all produced electricity. Computer electricity consumption in the year 2040 &lt;a href="https://www.sciencealert.com/computers-will-require-more-energy-than-the-world-generates-by-2040" target="_blank" rel="noopener noreferrer"&gt;could easily equal the total electricity production from the year 2016&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;A one percent compiler performance improvement in &lt;a href="https://en.wikipedia.org/wiki/Energy_proportional_computing" target="_blank" rel="noopener noreferrer"&gt;energy-proportional computing&lt;/a&gt; (an IT industry goal) means saving 25 terawatt-hours (TWh) out of the &lt;a href="https://en.wikipedia.org/wiki/Electricity_generation" target="_blank" rel="noopener noreferrer"&gt;25,000 TWh annual world electricity production&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Twenty-five terawatt-hours is equal to the average annual electricity production of six &lt;a href="https://www.usbr.gov/lc/hooverdam/faqs/powerfaq.html" target="_blank" rel="noopener noreferrer"&gt;Hoover dams&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="the-current-state-of-mir-project"&gt;&lt;img class="alignnone size-full wp-image-664697" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam.jpg" alt="" width="1200" height="797" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam.jpg 1200w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-300x199.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-768x510.jpg 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/hooverdam-1024x680.jpg 1024w" sizes="(max-width: 1200px) 100vw, 1200px" /&gt;&lt;/h2&gt; &lt;p&gt;Although the optimizing compiler topic is interesting to me, let us return to the MIR project description.&lt;/p&gt; &lt;h2 id="the-current-state-of-mir-project"&gt;The current state of the MIR project&lt;/h2&gt; &lt;p&gt;Figure 7 shows a diagram detailing the current state of the MIR project:&lt;/p&gt; &lt;div id="attachment_664787" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664787" class="wp-image-664787 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3-300x212.png" alt="Current MIR project diagram" width="300" height="212" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3-300x212.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir3.png 680w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664787" class="wp-caption-text"&gt;Figure 7: The current state of the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Currently, I can create MIR through an API or from MIR textual or binary representation. The MIR binary representation is up to 10 times more compact and up to 10 times faster to read than the textual one.&lt;/p&gt; &lt;p&gt;I can interpret MIR code and generate AMD64 machine code in memory from MIR. Recently, I got rid of the only external dependency used by the MIR interpreter, the &lt;a href="https://sourceware.org/libffi" target="_blank" rel="noopener noreferrer"&gt;Libffi&lt;/a&gt; foreign function interface library.&lt;/p&gt; &lt;p&gt;I can generate C code from MIR, and I am working on a C-to-MIR compiler, which is about 90% done in my opinion.&lt;/p&gt; &lt;h2 id="possible-future-directions-of-mir-project"&gt;Possible future directions for the MIR project&lt;/h2&gt; &lt;p&gt;Figure 8 shows the possible development directions for this project:&lt;/p&gt; &lt;div id="attachment_664797" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664797" class="wp-image-664797 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall-300x190.png" alt="ossible future development directions for the MIR project." width="300" height="190" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall-300x190.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mirall.png 740w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664797" class="wp-caption-text"&gt;Figure 8: Possible future development directions for the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Generating MIR from &lt;a href="https://llvm.org/docs/LangRef.html" target="_blank" rel="noopener noreferrer"&gt;LLVM internal representation&lt;/a&gt; permits the use of code from different languages implemented with LLVM; for example, Rust or &lt;a href="https://crystal-lang.org" target="_blank" rel="noopener noreferrer"&gt;Crystal&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Generating MIR from &lt;a href="https://en.wikipedia.org/wiki/Java_bytecode" target="_blank" rel="noopener noreferrer"&gt;Java bytecode&lt;/a&gt; would allow the same for languages implemented with &lt;a href="https://en.wikipedia.org/wiki/Java_virtual_machine" target="_blank" rel="noopener noreferrer"&gt;JVM&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Generating &lt;a href="https://webassembly.org" target="_blank" rel="noopener noreferrer"&gt;WebAssembly&lt;/a&gt; from MIR could allow using MIR code in web browsers. Actually, MIR features are pretty close to these of WebAssembly. The only big difference is that WebAssembly is a stack-based internal representation, and MIR is a register-based one.&lt;/p&gt; &lt;p&gt;There will be many interesting possibilities if all the directions are implemented.&lt;/p&gt; &lt;h2 id="mir-generator"&gt;MIR generator&lt;/h2&gt; &lt;p&gt;Currently, the most interesting component, at least for me, is the MIR generator producing optimized machine code. Figure 9 shows how it works:&lt;/p&gt; &lt;div id="attachment_664807" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664807" class="wp-image-664807 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-300x146.png" alt="Flow chart for the MIR generator." width="300" height="146" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-300x146.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen-768x375.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir-gen.png 820w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664807" class="wp-caption-text"&gt;Figure 9: The process the MIR generator follows.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Here is the process in more detail. First, we simplify MIR as much as possible, which means only using register indirect memory addressing. It also means that immediate instruction operands are used only in move instructions. During this pass, we also remove unused instructions through local value numbering.&lt;/p&gt; &lt;p&gt;Then, we inline function calls represented by the MIR instructions &lt;code&gt;inline&lt;/code&gt; and &lt;code&gt;call&lt;/code&gt;and, after that, build the &lt;a href="https://en.wikipedia.org/wiki/Control-flow_graph" target="_blank" rel="noopener noreferrer"&gt;control-flow graph&lt;/a&gt; (CFG)—in other words, the &lt;a href="https://en.wikipedia.org/wiki/Basic_block" target="_blank" rel="noopener noreferrer"&gt;basic blocks&lt;/a&gt; and edges between them. Next, we transform code to reuse already calculated values in global scope through so-called &lt;a href="https://en.wikipedia.org/wiki/Common_subexpression_elimination" target="_blank" rel="noopener noreferrer"&gt;global common subexpression elimination&lt;/a&gt; (GCSE). This step is an important optimization for inlined code.&lt;/p&gt; &lt;p&gt;The next pass mostly removes instructions found redundant on the previous pass through a dead code elimination optimization. Then, we do &lt;a href="https://en.wikipedia.org/wiki/Sparse_conditional_constant_propagation" target="_blank" rel="noopener noreferrer"&gt;sparse conditional constant propagation&lt;/a&gt; (SCCP). This step is also an important optimization for inlined code when there are constant call arguments. We also find that there can be constant expression values.&lt;/p&gt; &lt;p&gt;Constant values can switch off CFG paths during any execution. Switching off these paths can make other values constant, too. SCCP is a combined optimization, which means its result is better than performing the two separate optimizations of constant propagation and removing unused CFG paths.&lt;/p&gt; &lt;p&gt;After that, we run the machine-dependent code. Most x86 instructions, for example, additionally require the instruction result operand to be the same as one of the input operands. Therefore, the machine-dependent code is run to produce two-operand instructions. This code also generates additional MIR instructions for call parameter passing and returns.&lt;/p&gt; &lt;p&gt;The next step is to find &lt;a href="https://web.cs.wpi.edu/~kal/PLT/PLT8.6.4.html" target="_blank" rel="noopener noreferrer"&gt;natural loops&lt;/a&gt; in the MIR code CFG. This information will be used for the subsequent register allocation. Then, we calculate &lt;a href="https://en.wikipedia.org/wiki/Live_variable_analysis" target="_blank" rel="noopener noreferrer"&gt;live information&lt;/a&gt; for MIR variables. In the compiler world, this technique is known as a backward &lt;a href="https://en.wikipedia.org/wiki/Data-flow_analysis" target="_blank" rel="noopener noreferrer"&gt;data-flow problem&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once that work is complete, we calculate program points where MIR variables live. This info is used in a fast register allocator that assigns target hard registers, or stack slots, to MIR variables and removes various copy instructions. After the register assignment, we rewrite the MIR code, changing variables to the assigned hard registers or stack slots.&lt;/p&gt; &lt;p&gt;Then, we try to combine pairs of data-dependent MIR instructions into ones whose forms can represent a machine instruction. This is an instruction selection task. This pass also does &lt;a href="https://en.wikipedia.org/wiki/Copy_propagation" target="_blank" rel="noopener noreferrer"&gt;copy propagation&lt;/a&gt; optimization.&lt;/p&gt; &lt;p&gt;After instruction combining, there are usually many instructions whose output is never used. We delete such instructions. And then, finally, we generate machine code in memory. Each MIR instruction is encoded by a machine instruction. For AMD64, the encoding can be complicated.&lt;/p&gt; &lt;h2 id="some-mir-generator-features"&gt;MIR generator features&lt;/h2&gt; &lt;p&gt;These days, most compiler optimizations are implemented for &lt;a href="https://en.wikipedia.org/wiki/Static_single_assignment_form" target="_blank" rel="noopener noreferrer"&gt;static single assignment form&lt;/a&gt;. This is a special form of IR where we have only one assignment to each variable in the function IR. It was invented by IBM researchers a long time ago.&lt;/p&gt; &lt;p&gt;Using SSA simplifies the optimization implementations, but building and destroying this form is expensive. Using SSA for the MIR generator&amp;#8217;s short-pass pipeline makes little sense to me, so I don&amp;#8217;t use it.&lt;/p&gt; &lt;p&gt;Also, I don&amp;#8217;t generate position-independent code. I don&amp;#8217;t see any reasons to do this now. Generating such code is more complicated and decreases performance. For the AMD Geode processor (used in one version of the laptop for the &lt;a href="https://en.wikipedia.org/wiki/One_Laptop_per_Child" target="_blank" rel="noopener noreferrer"&gt;One Laptop per Child initiative&lt;/a&gt;) the performance decrease achieved 7%. For modern processors, the performance decrease is much smaller but still exists.&lt;/p&gt; &lt;h2 id="possible-ways-to-compile-c-to-mir"&gt;Possible ways to compile C to MIR&lt;/h2&gt; &lt;p&gt;To start using MIR in CRuby, I need a C-to-MIR compiler. There are several ways to implement this feature. I could implement an LLVM IR-to-MIR compiler or write a GCC port targeting MIR, but doing this would create a big dependency on a particular external project. It is not an easy task either. Once, I worked in a team that specialized in porting GCC to new targets and the standard estimation was at least six months of work to create a simple &amp;#8220;hello, world&amp;#8221; program.&lt;/p&gt; &lt;p&gt;On the other hand, people have written small C compilers pretty quickly. Here, I can mention the &lt;a href="https://en.wikipedia.org/wiki/Tiny_C_Compiler" target="_blank" rel="noopener noreferrer"&gt;Tiny C Compiler&lt;/a&gt;, and the recent &lt;a href="https://github.com/rui314/8cc" target="_blank" rel="noopener noreferrer"&gt;8cc&lt;/a&gt; and &lt;a href="https://github.com/rui314/9cc" target="_blank" rel="noopener noreferrer"&gt;9cc&lt;/a&gt; compiler projects.&lt;/p&gt; &lt;p&gt;So, I decided to write my own C-to-MIR compiler first. This compiler should implement standard C11 without optional features, such as variable arrays, complex numbers, and atomic data.&lt;/p&gt; &lt;p&gt;The major goal is simplicity, not speed. Again, doing this makes studying the code easier for other people and reduces the effort required to maintain it.&lt;/p&gt; &lt;h3 id="c-to-mir-compiler"&gt;C-to-MIR compiler&lt;/h3&gt; &lt;p&gt;Simplicity is usually achieved by dividing tasks into small, manageable subtasks. There is even an extreme &lt;a href="https://www.cs.indiana.edu/~dyb/pubs/nano-jfp.pdf" target="_blank" rel="noopener noreferrer"&gt;nanopass compiler design&lt;/a&gt; used for studying compiler topics in education.&lt;/p&gt; &lt;p&gt;My approach to the C compiler implementation is classic division on four passes of approximately the same size, as shown in Figure 10:&lt;/p&gt; &lt;div id="attachment_664777" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664777" class="wp-image-664777 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-300x62.png" alt="Flow chart for the C-to-MIR compiler." width="300" height="62" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-300x62.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c-768x160.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/mir2c.png 780w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664777" class="wp-caption-text"&gt;Figure 10: The C-to-MIR compiler approach.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I don&amp;#8217;t use any tools for the compiler, like YACC. Also, I don&amp;#8217;t modify the ANSI standard grammar, although it is &lt;a href="https://en.wikipedia.org/wiki/Ambiguous_grammar" target="_blank" rel="noopener noreferrer"&gt;ambiguous&lt;/a&gt;. I use a parsing expression grammar (&lt;a href="https://en.wikipedia.org/wiki/Parsing_expression_grammar" target="_blank" rel="noopener noreferrer"&gt;PEG&lt;/a&gt;) manual parser. It is a parser with moderate backtracking and it is simple and small but a bit slower than &lt;a href="https://en.wikipedia.org/wiki/Deterministic_parsing" target="_blank" rel="noopener noreferrer"&gt;deterministic parsers&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The MIR-to-C compiler is mostly implemented. It passes around 1,000 tests from different C test suites. Recently, I achieved an important milestone: a successful bootstrap. The new &lt;code&gt;c2m&lt;/code&gt; compiles its own sources and generates a MIR binary. The execution of this MIR binary processes &lt;code&gt;c2m&lt;/code&gt; sources again and generates another MIR binary, and the two MIR binary files are identical (option &lt;code&gt;-el&lt;/code&gt; of the &lt;code&gt;c2m&lt;/code&gt; invocation that follows means the execution of generated MIR code through lazy machine code generation):&lt;/p&gt; &lt;pre&gt; cc -O3 -fno-tree-sra -std=gnu11 -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -ldl -o c2m ./c2m -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -o 1.bmir ./c2m 1.bmir -el -Dx86_64 -I. mir-gen.c c2mir.c c2mir-driver.c mir.c -o 2.bmir&lt;/pre&gt; &lt;p&gt;Still, a lot of effort should be made to finish the missing obligatory C11 standard features (e.g., wide characters), achieve full call ABI compatibility, generate more efficient code for switches, and implement the GCC C extensions necessary for the CRuby JIT implementation.&lt;/p&gt; &lt;h3 id="llvm-ir-to-mir-compiler"&gt;LLVM IR-to-MIR compiler&lt;/h3&gt; &lt;p&gt;I am also working on an LLVM IR-to-MIR compiler. Currently, I am focusing on translating the LLVM IR produced by Clang from standard C code. Doing so will be useful when we want to generate more optimized MIR code and don&amp;#8217;t need a fast C compiler (e.g., when building a MIR-based JIT for a programming language).&lt;/p&gt; &lt;p&gt;The only missing part now is the translation of composite values, which are generated by Clang in rare cases when passing small structures in function calls or returning them from function calls. In the future, this translator could be extended to support code generated from other programming languages implemented with LLVM, such as Rust.&lt;/p&gt; &lt;p&gt;I hope that &lt;a href="https://llvm.org/devmtg/2019-10/" target="_blank" rel="noopener noreferrer"&gt;LLVM IR will stabilize in the near future&lt;/a&gt; and no extensive maintenance will be necessary.&lt;/p&gt; &lt;h2 id="possible-ways-to-use-mir-for-cruby-mjit"&gt;Possible ways to use MIR for CRuby MJIT&lt;/h2&gt; &lt;p&gt;So how do I plan to use the MIR project for CRuby? Figure 11 shows how the current MJIT works:&lt;/p&gt; &lt;div id="attachment_664847" style="width: 636px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664847" class="wp-image-664847 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0.png" alt="Diagram showing how the current MJIT works." width="626" height="418" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0.png 626w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT0-300x200.png 300w" sizes="(max-width: 626px) 100vw, 626px" /&gt;&lt;p id="caption-attachment-664847" class="wp-caption-text"&gt;Figure 11: How the current MJIT works.&lt;/p&gt;&lt;/div&gt; &lt;h3 id="mir-compiler-as-a-tier1-jit-compiler-in-cruby"&gt;MIR compiler as a tier-one JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;Figure 12 shows how the future MJIT would look after implementing a MIR-based JIT compiler as a tier-one compiler:&lt;/p&gt; &lt;div id="attachment_664857" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664857" class="wp-image-664857 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1.png" alt="How the future MJIT would look after implementing a MIR-based JIT compiler as a tier one compiler." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT1-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664857" class="wp-caption-text"&gt;Figure 12: How the future MJIT would look after implementing a MIR-based JIT compiler as a tier-one compiler.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The blue parts show the new data-flow for MJIT. When building CRuby, we could generate MIR code for the standard Ruby methods written in C. We can load this MIR code as a MIR binary. This part could be done very quickly.&lt;/p&gt; &lt;p&gt;MJIT could create MIR code for a Ruby method through the MIR API. This MIR code could inline the already existing MIR code functions. The corresponding machine code can be generated by the MIR generator. This is a fast method, but we could also generate machine code by translating MIR into C and then using GCC or LLVM. This is a much slower method, but it permits us to use the full spectrum of GCC/LLVM optimizations, plus it permits efficient implementation of inlining C code into Ruby code and vice versa.&lt;/p&gt; &lt;h3 id="mir-compiler-as-a-single-jit-compiler-in-cruby"&gt;MIR compiler as a single JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;For some environments, the MIR JIT compiler could be used as a single JIT compiler. In this case, MIR with MJIT would look as you see in Figure 13:&lt;/p&gt; &lt;div id="attachment_664867" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664867" class="wp-image-664867 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2.png" alt="Diagram showing how the MIR compiler would work as a single JIT compiler in CRuby." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT2-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664867" class="wp-caption-text"&gt;Figure 13: How the MIR compiler would work as a single JIT compiler in CRuby.&lt;/p&gt;&lt;/div&gt; &lt;h3 id="mir-compiler-and-c-to-mir-compiler-as-a-single-jit-compiler-in-cruby"&gt;MIR compiler and C-to-MIR compiler as a single JIT compiler in CRuby&lt;/h3&gt; &lt;p&gt;Instead of directly generating MIR for the JIT compiler, we could generate C code first and translate it into MIR with the C-to-MIR translator. In this case, MJIT would look as you see in Figure 14:&lt;/p&gt; &lt;div id="attachment_664877" style="width: 637px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664877" class="wp-image-664877 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3.png" alt="Diagram showing how the MIR compiler combined with the C-to-MIR compiler would work in CRuby." width="627" height="481" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3.png 627w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/SMJIT3-300x230.png 300w" sizes="(max-width: 627px) 100vw, 627px" /&gt;&lt;p id="caption-attachment-664877" class="wp-caption-text"&gt;Figure 14: How the MIR compiler combined with the C-to-MIR compiler would work in CRuby.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;I discussed the lightweight JIT compiler project with a few people, and two of them independently wanted to generate C code for JIT. It would make their life easier to use a MIR-based JIT compiler for their own JIT implementations.&lt;/p&gt; &lt;p&gt;The C-to-MIR JIT compiler is pretty small, has a fast startup, and can be used as a library to read the generated C code from memory. Although the C-to-MIR translator was not designed to be fast, it is still about 15 times faster than GCC with -O2. All of this makes such an approach viable.&lt;/p&gt; &lt;h2 id="current-performance-results"&gt;Current performance results&lt;/h2&gt; &lt;p&gt;And finally, here are the current performance results for the MIR generator and interpreter compared to GCC-8.2.1. I used the sieve benchmark on an Intel i7-9700K machine running Fedora Core 29. The sieve C code has no include directives and is only about 30 preprocessed lines:&lt;/p&gt; &lt;table align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;&lt;/th&gt; &lt;th&gt;MIR-gen&lt;/th&gt; &lt;th&gt;MIR-interp&lt;/th&gt; &lt;th&gt;gcc -O2&lt;/th&gt; &lt;th&gt;gcc -O0&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;compilation [1]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (75us)&lt;/td&gt; &lt;td&gt;0.16 (12us)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;178&lt;/strong&gt; (13.35ms)&lt;/td&gt; &lt;td&gt;171 (12.8ms)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;execution [2]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (3.1s)&lt;/td&gt; &lt;td&gt;5.9 (18.3s)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;0.94&lt;/strong&gt; (2.9s)&lt;/td&gt; &lt;td&gt;2.05 (6.34s)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;code size [3]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (175KB)&lt;/td&gt; &lt;td&gt;0.65 (114KB)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;144&lt;/strong&gt; (25.2MB)&lt;/td&gt; &lt;td&gt;144 (25.2MB)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;startup [4]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (1.3us)&lt;/td&gt; &lt;td&gt;1.0 (1.3us)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;9310&lt;/strong&gt; (12.1ms)&lt;/td&gt; &lt;td&gt;9850 (12.8ms)&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;LOC [5]&lt;/td&gt; &lt;td&gt;&lt;strong&gt;1.0&lt;/strong&gt; (16K)&lt;/td&gt; &lt;td&gt;0.56 (9K)&lt;/td&gt; &lt;td&gt;&lt;strong&gt;93&lt;/strong&gt; (1480K)&lt;/td&gt; &lt;td&gt;93 (1480K)&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;The compilation speed of the MIR-generator is about 180 times faster than GCC with -O2. It takes 80 microseconds to generate the code for the sieve. And the sieve code generated by the MIR generator is only 6% slower.&lt;/p&gt; &lt;p&gt;The MIR generator&amp;#8217;s object size is much smaller than the object size of &lt;code&gt;cc1&lt;/code&gt;. MIR generator has a fast startup time and is suitable for use as a tier1 JIT compiler.&lt;/p&gt; &lt;p&gt;Here are the notes for each table row:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;[1]: Wall time of compilation of sieve code (without any include file and with using the memory file system for GCC).&lt;/li&gt; &lt;li&gt;[2]: The best wall time of 10 runs.&lt;/li&gt; &lt;li&gt;[3]: The stripped sizes of &lt;code&gt;cc1&lt;/code&gt; for GCC, and the MIR core and interpreter or generator for MIR.&lt;/li&gt; &lt;li&gt;[4]: Wall time of object code generation for an empty C file, or of the generation of an empty MIR module through the API.&lt;/li&gt; &lt;li&gt;[5]: Based only on the files required for the AMD64 C compiler and the minimal number of files required to create and run MIR code.&lt;/li&gt; &lt;/ul&gt; &lt;h2 id="current-mir-sloc-distribution"&gt;Current MIR SLOC distribution&lt;/h2&gt; &lt;p&gt;Figure 15 shows a source line distribution for the current version of the MIR project. The MIR-to-C compiler is about 12 thousand lines of C code. MIR core is about nine thousand lines:&lt;/p&gt; &lt;div id="attachment_664947" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-664947" class="wp-image-664947 size-medium" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1-300x225.png" alt="A source line distribution for the current version of the MIR project." width="300" height="225" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1-300x225.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/size-chart-1.png 756w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;p id="caption-attachment-664947" class="wp-caption-text"&gt;Figure 15: A source line distribution for the current version of the MIR project.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The MIR generator is less than five thousand lines.&lt;/p&gt; &lt;p&gt;Machine-dependent code used by the generator is about two thousand lines, so you can estimate the effort required to port the MIR generator to another target. For example, I expect that porting MIR to &lt;a href="https://en.wikipedia.org/wiki/ARM_architecture#AArch64" target="_blank" rel="noopener noreferrer"&gt;Aarch64&lt;/a&gt; will take me about one to two months of work.&lt;/p&gt; &lt;h2 id="competitors-of-the-mir-project"&gt;MIR project competitors&lt;/h2&gt; &lt;p&gt;I&amp;#8217;ve been studying JITs for a long time. Before starting the MIR project, I thought about adapting the existing code. Here is a comparison of MIR with the simple compiler projects I considered:&lt;/p&gt; &lt;table align="center"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Project&lt;/th&gt; &lt;th&gt;SLOC&lt;/th&gt; &lt;th&gt;License&lt;/th&gt; &lt;th&gt;IR type&lt;/th&gt; &lt;th&gt;Major Optimizations&lt;/th&gt; &lt;th&gt;Output&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;MIR&lt;/td&gt; &lt;td&gt;16K C&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;non-SSA&lt;/td&gt; &lt;td&gt;Inlining, GCSE, SCCP, RA, CP, DCE, LA&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;DotGNU LibJIT&lt;/td&gt; &lt;td&gt;80K C&lt;/td&gt; &lt;td&gt;LGPL&lt;/td&gt; &lt;td&gt;non-SSA&lt;/td&gt; &lt;td&gt;Only RA and primitive CP&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;.NET RyuJIT&lt;/td&gt; &lt;td&gt;360K C++&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;MIR ones minus SCCP plus LICM, Range&lt;/td&gt; &lt;td&gt;Binary code&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;QBE&lt;/td&gt; &lt;td&gt;10K C&lt;/td&gt; &lt;td&gt;MIT&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;MIR ones plus aliasing minus inlining&lt;/td&gt; &lt;td&gt;Assembler&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;LIBFirm&lt;/td&gt; &lt;td&gt;140K C&lt;/td&gt; &lt;td&gt;LGPL2&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;RA, Inlining, DCE, LICM, CP, LA, Others&lt;/td&gt; &lt;td&gt;Assembler&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;CraneLift&lt;/td&gt; &lt;td&gt;70K Rust&lt;/td&gt; &lt;td&gt;Apache&lt;/td&gt; &lt;td&gt;SSA&lt;/td&gt; &lt;td&gt;DCE, LICM, RA, GVN, CP, LA&lt;/td&gt; &lt;td&gt;Binary Code&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Here are the abbreviations used in the table:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;CP: &lt;a href="https://en.wikipedia.org/wiki/Copy_propagation" target="_blank" rel="noopener noreferrer"&gt;Copy propagation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;DCE: &lt;a href="https://en.wikipedia.org/wiki/Dead_code_elimination" target="_blank" rel="noopener noreferrer"&gt;Dead code elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GCSE: &lt;a href="https://en.wikipedia.org/wiki/Common_subexpression_elimination" target="_blank" rel="noopener noreferrer"&gt;Global common sub-expression elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;GVN: &lt;a href="https://en.wikipedia.org/wiki/Value_numbering" target="_blank" rel="noopener noreferrer"&gt;Global value numbering&lt;/a&gt;&lt;/li&gt; &lt;li&gt;LA: Finding loops in CFG&lt;/li&gt; &lt;li&gt;LICM: &lt;a href="https://en.wikipedia.org/wiki/Loop-invariant_code_motion" target="_blank" rel="noopener noreferrer"&gt;Loop invariant code motion&lt;/a&gt;&lt;/li&gt; &lt;li&gt;RA: &lt;a href="https://en.wikipedia.org/wiki/Register_allocation" target="_blank" rel="noopener noreferrer"&gt;Register allocation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Range: &lt;a href="https://en.wikipedia.org/wiki/Value_range_analysis" target="_blank" rel="noopener noreferrer"&gt;Range analysis&lt;/a&gt;&lt;/li&gt; &lt;li&gt;SCCP: &lt;a href="https://en.wikipedia.org/wiki/Sparse_conditional_constant_propagation" target="_blank" rel="noopener noreferrer"&gt;Sparse conditional constant propagation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Others include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Partial_redundancy_elimination" target="_blank" rel="noopener noreferrer"&gt;Partial redundancy elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Loop_unrolling" target="_blank" rel="noopener noreferrer"&gt;Loop unrolling&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Scalar replacement&lt;/li&gt; &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/1240539/what-is-tail-recursion-elimination" target="_blank" rel="noopener noreferrer"&gt;Tail recursion elimination&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Expression reassociation&lt;/li&gt; &lt;li&gt;Function cloning&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Strength_reduction" target="_blank" rel="noopener noreferrer"&gt;Strength reduction&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Loop_optimization" target="_blank" rel="noopener noreferrer"&gt;Loop optimizations&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Load store motion&lt;/li&gt; &lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Jump_threading" target="_blank" rel="noopener noreferrer"&gt;Jump threading&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;After studying these projects closely, I decided to start the MIR project. The biggest cons of the existing projects were their size, the fact that it would be hard for me to achieve my goals using them, and that I can not control the projects. Also, the smaller source size of the MIR project makes studying the code easier for other people and reduces the effort required to maintain it.&lt;/p&gt; &lt;h2 id="plans-for-mir-project"&gt;Plans for the MIR project&lt;/h2&gt; &lt;p&gt;The MIR project is pretty ambitious. I&amp;#8217;ve decided to develop it in an open way because this permits me to receive valuable feedback from many people in the project&amp;#8217;s early stages. You can follow the progress of the project on &lt;a href="https://github.com/vnmakarov/mir" target="_blank" rel="noopener noreferrer"&gt;GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Although MIR is still in the early stages of development, I plan to start using it for a CRuby/MRuby JIT implementation soon. It would be a useful way to improve the MIR compiler implementation and find missing features.&lt;/p&gt; &lt;p&gt;If the use of a MIR-based compiler for Ruby JIT is successful, I will work on the first release of the MIR project code, which I hope will be useful for JIT implementations of other programming languages.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#38;linkname=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F20%2Fmir-a-lightweight-jit-compiler-project%2F&amp;#038;title=MIR%3A%20A%20lightweight%20JIT%20compiler%20project" data-a2a-url="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/" data-a2a-title="MIR: A lightweight JIT compiler project"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/"&gt;MIR: A lightweight JIT compiler project&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PDvpKffeLA8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;For the past three years, I&amp;#8217;ve been participating in adding just-in-time compilation (JIT) to CRuby. Now, CRuby has the method-based just-in-time compiler (MJIT), which improves performance for non-input/output-bound programs. The most popular approach to implementing a JIT is to use LLVM or GCC JIT interfaces, like ORC or LibGCCJIT. GCC and LLVM developers spend huge effort to implement the optimizations reliably, effectively, and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/"&gt;MIR: A lightweight JIT compiler project&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">664687</post-id><dc:creator>Vladimir Makarov</dc:creator><dc:date>2020-01-20T08:00:32Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/20/mir-a-lightweight-jit-compiler-project/</feedburner:origLink></entry><entry><title>How to Install Red Hat Decision Manager 7.5 in Minutes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lk9j4gCEbcc/how-to-install-red-hat-decision-manager-75-in-minutes.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_decision_manager_7_5_in_minutes</id><updated>2020-01-20T10:19:51Z</updated><published>2020-01-20T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;a href="https://1.bp.blogspot.com/-cx9_jd_GvKs/XiAi_Q0TWTI/AAAAAAAAw2o/TnMQmCftBw0426Hhw6dp1WumTaIH1BxygCNcBGAsYHQ/s1600/rhdm-login.png" imageanchor="1" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="red hat decision manager" border="0" data-original-height="922" data-original-width="1600" height="184" src="https://1.bp.blogspot.com/-cx9_jd_GvKs/XiAi_Q0TWTI/AAAAAAAAw2o/TnMQmCftBw0426Hhw6dp1WumTaIH1BxygCNcBGAsYHQ/s320/rhdm-login.png" title="" width="320" /&gt;&lt;/a&gt;While you've seen the many &lt;a href="http://www.schabell.org/search/label/OpenShift" target="_blank"&gt;developer tooling articles&lt;/a&gt; where I've helped you to &lt;a href="https://gitlab.com/redhatdemocentral" target="_blank"&gt;get started on the OpenShift Container Platform&lt;/a&gt;, there is still a basic need to run our tooling locally on our own machine.&lt;br /&gt;&lt;br /&gt;With that in mind, here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine.&lt;br /&gt;&lt;br /&gt;Not only that, it's done in just three easy steps and done in a few minutes!&lt;br /&gt;&lt;br /&gt;See if I'm telling the truth, let's install it now:&lt;br /&gt;&lt;a href="https://www.blogger.com/u/2/null" name="more"&gt;&lt;/a&gt;&lt;br /&gt;Just three easy steps to a fully installed and configured Red Hat Decision Manager.&lt;br /&gt;&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 data-sourcepos="6:1-8:122" dir="auto"&gt;&lt;a href="https://1.bp.blogspot.com/-MYe4WtgtarE/XiAjIrr54YI/AAAAAAAAw2s/WuIh09qu3GQRHhuN1OJ43GlVpNmgCRsIwCNcBGAsYHQ/s1600/rhdm-decision-central.png" imageanchor="1" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat decision manager" border="0" data-original-height="936" data-original-width="1600" height="187" src="https://1.bp.blogspot.com/-MYe4WtgtarE/XiAjIrr54YI/AAAAAAAAw2s/WuIh09qu3GQRHhuN1OJ43GlVpNmgCRsIwCNcBGAsYHQ/s320/rhdm-decision-central.png" title="" width="320" /&gt;&lt;/a&gt;Install on your machine&lt;/h2&gt;There are a few component you'll need to download for free from the provided developers site, then obtain the project linked below, add the downloads, and run the installation script.&lt;span id="goog_1798584621"&gt;&lt;/span&gt;&lt;br /&gt;&lt;div style="text-align: right;"&gt;&lt;br /&gt;&lt;/div&gt;Watch the installation unfold before your eyes, with configuration, settings, and user creation all detailed in the script output so you can learn from the installation.&lt;br /&gt;&amp;nbsp; &lt;br /&gt;&lt;div&gt;Give it a try with these three steps:&lt;br /&gt;&lt;ol&gt;&lt;li data-sourcepos="8:1-9:0"&gt;&lt;div data-sourcepos="8:4-8:120"&gt;&lt;a href="https://gitlab.com/bpmworkshop/rhdm-install-demo/-/archive/master/rhdm-install-demo-master.zip" target="_blank"&gt;Download and unzip.&lt;/a&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="10:1-11:0"&gt;&lt;div data-sourcepos="10:4-10:81"&gt;Add products to installs directory, see installs/README for details and links.&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="14:1-15:0"&gt;&lt;div data-sourcepos="12:4-12:90"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges&lt;/div&gt;&lt;div data-sourcepos="12:4-12:90"&gt;&lt;br /&gt;&lt;/div&gt;&amp;nbsp;Log in to http://localhost:8080/decision-central (u:erics / p:redhatdm1!)&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;That's it, not it's time to enjoy your installed and configured Red Hat Decision Manager.&lt;br /&gt;&lt;br /&gt;Not sure how to get started with process automation? Try one of these &lt;a href="https://bpmworkshop.gitlab.io/index-redhat.html#/2" rel=" noreferrer noopener" target="_blank"&gt;online workshops&lt;/a&gt; to build a first project from scratch.&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F3p_4S64mzc:ZP60ppfXUY4:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F3p_4S64mzc:ZP60ppfXUY4:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F3p_4S64mzc:ZP60ppfXUY4:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=F3p_4S64mzc:ZP60ppfXUY4:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=F3p_4S64mzc:ZP60ppfXUY4:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/F3p_4S64mzc" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lk9j4gCEbcc" height="1" width="1" alt=""/&gt;</content><summary>While you've seen the many developer tooling articles where I've helped you to get started on the OpenShift Container Platform, there is still a basic need to run our tooling locally on our own machine. With that in mind, here's an update that installs the latest process automation tooling for your development projects in just minutes on your very own machine. Not only that, it's done in just thre...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-20T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/F3p_4S64mzc/how-to-install-red-hat-decision-manager-75-in-minutes.html</feedburner:origLink></entry><entry><title>Byteman 4.0.10 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LwdxEE61kmU/byteman-4010-has-been-released.html" /><category term="feed_group_name_byteman" scheme="searchisko:content:tags" /><category term="feed_name_byteman" scheme="searchisko:content:tags" /><author><name>Andrew Dinn</name></author><id>searchisko:content:id:jbossorg_blog-byteman_4_0_10_has_been_released</id><updated>2020-01-17T11:58:00Z</updated><published>2020-01-17T11:58:00Z</published><content type="html">Byteman 4.0.10 is now available from the &lt;a href="http://www.jboss.org/byteman/downloads"&gt;Byteman downloads page&lt;/a&gt; and from the &lt;a href="https://oss.sonatype.org/index.html#nexus-search;quick%7Ebyteman"&gt;Maven Central repository&lt;/a&gt;. It is the latest update release for use on all JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes.&lt;br /&gt;&lt;br /&gt;Byteman 4.0.10 is a maintenance release which fixes a regression introduced in 4.0.9 and extends the range of supported JDK releases to include JDK15. More details are provided in the &lt;a href="http://downloads.jboss.org/byteman/latest/ReleaseNotes.txt"&gt;Release Notes&lt;/a&gt;.&lt;br /&gt; &lt;span class="post-author vcard"&gt;&lt;br /&gt;&lt;/span&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LwdxEE61kmU" height="1" width="1" alt=""/&gt;</content><summary>Byteman 4.0.10 is now available from the Byteman downloads page and from the Maven Central repository. It is the latest update release for use on all JDK9+ runtimes. It is also recommended as the preferred release for use on JDK8- runtimes. Byteman 4.0.10 is a maintenance release which fixes a regression introduced in 4.0.9 and extends the range of supported JDK releases to include JDK15. More det...</summary><dc:creator>Andrew Dinn</dc:creator><dc:date>2020-01-17T11:58:00Z</dc:date><feedburner:origLink>http://bytemanblog.blogspot.com/2020/01/byteman-4010-has-been-released.html</feedburner:origLink></entry><entry><title>Deploying applications in the OpenShift 4.3 Developer perspective</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cH7vyj98N18/" /><category term="Containers" /><category term="Developer Tools" /><category term="Operator" /><category term="application deployment" /><category term="Developer Perspective" /><category term="OpenShift 4.3" /><category term="user flow" /><author><name>Steve Speicher</name></author><id>https://developers.redhat.com/blog/?p=673837</id><updated>2020-01-17T08:00:53Z</updated><published>2020-01-17T08:00:53Z</published><content type="html">&lt;p&gt;In this article, we take a look at user flow improvements for deploying applications in &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift 4.3&lt;/a&gt;&amp;#8216;s Developer perspective. You can learn more about all of the developer-focused console improvements in the &lt;a href="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/"&gt;OpenShift 4.3 release article here&lt;/a&gt;. Since the initial launch of the Developer perspective in the OpenShift 4.2 release, we’ve had frequent feedback sessions with developers, developer advocates, stakeholders, and other community members to better understand how the experience meets their needs. While, overall, the user interface has been well received, we continue to gather and use the feedback to enhance our flows.&lt;/p&gt; &lt;h2&gt;The Add page&lt;/h2&gt; &lt;p&gt;Added in OpenShift 4.2, the &lt;strong&gt;+Add&lt;/strong&gt; option in the left navigation portion of the Developer perspective, as shown in Figure 1, is the entry point for developers to add an application or service to their OpenShift project.&lt;/p&gt; &lt;div id="attachment_674647" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-674647" class="wp-image-674647 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Add-1024x534.png" alt="OpenShift Developer perspective Add page." width="640" height="334" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Add-1024x534.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Add-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Add-768x400.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-674647" class="wp-caption-text"&gt;Figure 1: Add an application or service to your OpenShift project using these six user flows.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As you can see, the &lt;strong&gt;Add&lt;/strong&gt; page offers six user flows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Adding components from Git.&lt;/li&gt; &lt;li&gt;Deploying container images.&lt;/li&gt; &lt;li&gt;Adding an item from the developer catalog.&lt;/li&gt; &lt;li&gt;Importing your Dockerfile from a Git repo.&lt;/li&gt; &lt;li&gt;Importing YAML.&lt;/li&gt; &lt;li&gt;Adding a Database.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;&lt;strong&gt;OpenShift 4.3 user flow improvements&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;The release of OpenShift 4.3 brings improvements to the &lt;strong&gt;Import from git&lt;/strong&gt; and &lt;strong&gt;Deploy Image&lt;/strong&gt; flows. Let&amp;#8217;s take a look at each.&lt;/p&gt; &lt;h3&gt;Builder image detection for &lt;strong&gt;Import from git&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Import from git&lt;/strong&gt; flow has been enhanced to help users easily create applications by auto-filling in the details, making the process more automated. This improvement comes from introducing auto-detection for the builder image, which provides assistance in determining the right build strategy.&lt;/p&gt; &lt;p&gt;In 4.3, as soon as the user enters a &lt;strong&gt;Git Repo URL&lt;/strong&gt;, URL validation takes place. Once the URL is validated, the builder image detection process starts. The recommended builder image is indicated with a star and is selected by default, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_674637" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-674637" class="wp-image-674637 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/BuilderImageDetection-1024x533.gif" alt="The Import from git build image detection process." width="640" height="333" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/BuilderImageDetection-1024x533.gif 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/BuilderImageDetection-300x156.gif 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/BuilderImageDetection-768x400.gif 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-674637" class="wp-caption-text"&gt;Figure 2: Importing from Git triggers builder image detection.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;By suggesting a builder image, we try to reduce the number of steps it takes users to build their application. However, the user is free to select a different builder image manually. To further increase the flow&amp;#8217;s efficiency, the &lt;strong&gt;Application&lt;/strong&gt; and &lt;strong&gt;Name&lt;/strong&gt; fields are populated with smart defaults based on the &lt;strong&gt;Git Repo URL&lt;/strong&gt; entered. These fields can also be edited if they are not what the user wants. Providing the user with optional suggestions in these form fields helps the user proceed faster without mandating what they enter.&lt;/p&gt; &lt;h3&gt;Deploy an image from an image stream&lt;/h3&gt; &lt;p&gt;The &lt;strong&gt;Deploy Image&lt;/strong&gt; flow now offers the ability to deploy an image using an image name from an internal registry, as shown in Figure 3. This option was present in the 3.11 release of OpenShift and is being reintroduced in 4.3 with enhancements.&lt;/p&gt; &lt;div id="attachment_674627" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-674627" class="wp-image-674627 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Imagestreamtagselected-1004x1024.png" alt="The OpenShift Deploy Image screen with an internal registry selected." width="640" height="653" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Imagestreamtagselected-1004x1024.png 1004w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Imagestreamtagselected-294x300.png 294w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Imagestreamtagselected-768x783.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-674627" class="wp-caption-text"&gt;Figure 3: Deploy an image using an image name from an internal registry.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When choosing this option, the user identifies the container image to be deployed by selecting the associated project, image streams, and tag in the &lt;b&gt;Image&lt;/b&gt; section of the form, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_674617" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-674617" class="wp-image-674617 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Grantusercheckbox-1024x476.png" alt="The OpenShift Deploy Image screen with an internal registry selected and defined." width="640" height="298" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Grantusercheckbox-1024x476.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Grantusercheckbox-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Grantusercheckbox-768x357.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-674617" class="wp-caption-text"&gt;Figure 4: An example internal registry deployment.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;To improve this flow from 3.11, upon project selection, we verify that there is proper access to pull images from this project. When there isn’t proper access, the user can choose to grant that access via a checkbox, which is selected by default.&lt;/p&gt; &lt;h2&gt;&lt;strong&gt;The new &lt;/strong&gt;&lt;strong&gt;Resources section&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;In the 4.2 initial release of the Developer perspective, the &lt;strong&gt;Import from Git&lt;/strong&gt;, &lt;strong&gt;Import from Dockerfile&lt;/strong&gt;, and &lt;strong&gt;Deploy Image&lt;/strong&gt; user flows created deployment configs by default. When the Serverless Operator was installed, a Serverless section was displayed allowing the user to select a checkbox indicating that they wanted a Knative service to be created.&lt;/p&gt; &lt;p&gt;In 4.3, we added a &lt;b&gt;Resources&lt;/b&gt; section to these flows that allows the user to select what type of resource to create, as shown in Figure 5. The default is a Kubernetes &lt;strong&gt;Deployment&lt;/strong&gt;. Other resource types available for selection are &lt;strong&gt;Deployment Config&lt;/strong&gt; and &lt;strong&gt;Knative Service&lt;/strong&gt;. The &lt;strong&gt;Knative Service&lt;/strong&gt; option is only available when the OpenShift Serverless Operator is installed. Because these forms are dynamic and change based on user selections, the &lt;strong&gt;Advanced Options&lt;/strong&gt; available will differ depending on the resource that is selected.&lt;/p&gt; &lt;div id="attachment_674607" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-674607" class="wp-image-674607 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Resources-section-1024x530.png" alt="The OpenShift Resources section with a Kubernetes Deployment selected." width="640" height="331" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/Resources-section-1024x530.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Resources-section-300x155.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/Resources-section-768x398.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-674607" class="wp-caption-text"&gt;Figure 5: Choose the type of resource to create in the new Resources section.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;strong&gt;Learn more&lt;/strong&gt;&lt;/h2&gt; &lt;p&gt;Interested in learning more about application development with OpenShift? Check out the Red Hat resources for &lt;a href="http://developers.redhat.com/openshift"&gt;application development on OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;&lt;strong&gt;Provide feedback&lt;/strong&gt;&lt;/h3&gt; &lt;p&gt;Want to give us feedback? Join our &lt;a href="https://groups.google.com/forum/#!forum/openshift-dev-users" target="_blank" rel="noopener noreferrer"&gt;OpenShift Developer Experience Google Group&lt;/a&gt;, participate in discussions, or attend our Office Hours Feedback session. Or, drop us an &lt;a href="mailto:openshift-ux@redhat.com" target="_blank" rel="noopener noreferrer"&gt;email&lt;/a&gt; with your comments about the OpenShift console user experience.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#38;linkname=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fdeploying-applications-in-the-openshift-4-3-developer-perspective%2F&amp;#038;title=Deploying%20applications%20in%20the%20OpenShift%204.3%20Developer%20perspective" data-a2a-url="https://developers.redhat.com/blog/2020/01/17/deploying-applications-in-the-openshift-4-3-developer-perspective/" data-a2a-title="Deploying applications in the OpenShift 4.3 Developer perspective"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/17/deploying-applications-in-the-openshift-4-3-developer-perspective/"&gt;Deploying applications in the OpenShift 4.3 Developer perspective&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cH7vyj98N18" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, we take a look at user flow improvements for deploying applications in Red Hat OpenShift 4.3&amp;#8216;s Developer perspective. You can learn more about all of the developer-focused console improvements in the OpenShift 4.3 release article here. Since the initial launch of the Developer perspective in the OpenShift 4.2 release, we’ve had frequent [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/17/deploying-applications-in-the-openshift-4-3-developer-perspective/"&gt;Deploying applications in the OpenShift 4.3 Developer perspective&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">673837</post-id><dc:creator>Steve Speicher</dc:creator><dc:date>2020-01-17T08:00:53Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/17/deploying-applications-in-the-openshift-4-3-developer-perspective/</feedburner:origLink></entry><entry><title>.NET Core on Red Hat platforms</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/4tM1-disMJk/" /><category term=".NET Core" /><category term="Containers" /><category term="CentOS" /><category term="Fedora" /><category term="openshift" /><category term="RHEL" /><category term="UBI" /><author><name>Tom Deseyn</name></author><id>https://developers.redhat.com/blog/?p=671917</id><updated>2020-01-17T08:00:13Z</updated><published>2020-01-17T08:00:13Z</published><content type="html">&lt;p&gt;In this article, we look at the various ways .NET Core is made available on Red Hat platforms. We start with an overview of the available platforms, and then show how to install .NET Core on each of them.&lt;/p&gt; &lt;h2&gt;Platform overview&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s start with the overview. If you are familiar with these platforms already, you can skip to the sections that cover specific platforms.&lt;/p&gt; &lt;h3&gt;Operating systems&lt;/h3&gt; &lt;p&gt;From an operating system point of view, we’ll look at four distributions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://getfedora.org/" target="_blank" rel="noopener noreferrer"&gt;Fedora&lt;/a&gt; is a community maintained distribution that moves fast. It is a great option for developers who want access to the latest development tools and the latest kernel.&lt;/li&gt; &lt;li&gt;&lt;a href="http://developers.redhat.com/rhel8/"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) is a long-term support (LTS) distribution by Red Hat that is based on Fedora.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.centos.org/" target="_blank" rel="noopener noreferrer"&gt;CentOS&lt;/a&gt; is a community maintained downstream rebuild of Red Hat Enterprise Linux.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/transforming-development-experience-within-centos" target="_blank" rel="noopener noreferrer"&gt;CentOS Stream&lt;/a&gt; is a rolling preview distribution of future Red Hat Enterprise Linux versions.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;All of these distributions are &lt;em&gt;Free as in Freedom&lt;/em&gt;, so the software is available and open for change. Fedora and CentOS have no cost (&lt;em&gt;Free as in Beer&lt;/em&gt;). For Red Hat Enterprise Linux, you pay a support subscription to Red Hat. For development purposes, however, you can use a &lt;a href="https://developers.redhat.com/blog/2016/03/31/no-cost-rhel-developer-subscription-now-available/"&gt;no-cost Red Hat Developer subscription&lt;/a&gt; and download Red Hat Enterprise Linux, as well as our other products and tools at no cost.&lt;/p&gt; &lt;h3&gt;Containers&lt;/h3&gt; &lt;p&gt;Most public cloud vendors support creating Red Hat Enterprise Linux- and CentOS-based virtual machines (VMs). The VMs based on RHEL are supported by Red Hat, and the VMs based on CentOS are supported by the CentOS community.&lt;/p&gt; &lt;p&gt;With container technology, operating systems are now also packaged into container images. These images contain packages from the OS, but not the kernel. Red Hat provides Red Hat Enterprise Linux 7- and RHEL 8-based images. Red Hat Enterprise Linux 8-based images are based on the &lt;a href="https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image" target="_blank" rel="noopener noreferrer"&gt;Universal Base Image&lt;/a&gt; (UBI). For Red Hat Enterprise Linux 7, some images are provided as UBI images and others as non-UBI images. The RHEL 7 non-UBI images are hosted on &lt;a href="https://registry.redhat.io" target="_blank" rel="noopener noreferrer"&gt;registry.redhat.io&lt;/a&gt; and require subscription credentials to be pulled. The UBI images are hosted on &lt;a href="https://registry.access.redhat.com" target="_blank" rel="noopener noreferrer"&gt;registry.access.redhat.com&lt;/a&gt; and require no subscription for download. These images &lt;em&gt;may be used in production without a Red Hat subscription, on any platform&lt;/em&gt;. However, when the UBI images run on a Red Hat Enterprise Linux platform, subscribers get support from Red Hat. The CentOS community also provides images that are hosted on &lt;a href="https://registry.centos.org" target="_blank" rel="noopener noreferrer"&gt;registry.centos.org&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;OpenShift&lt;/h3&gt; &lt;p&gt;For running container-based applications, Red Hat provides &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;, which is based on &lt;a href="http://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;. Kubernetes provides the core functionality for scheduling containers across multiple machines. OpenShift packages Kubernetes in a form that is usable, deployable, and maintainable. Red Hat provides a supported version of OpenShift that can be deployed on-prem and in public clouds (e.g., Azure, AWS, and GCP). Red Hat OpenShift is based on the open source, upstream &lt;a href="https://www.okd.io/" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;okd&lt;/code&gt;&lt;/a&gt; project. To run OpenShift on your development machine, you can use &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; (CRC) for OpenShift 4.x, and the &lt;a href="https://developers.redhat.com/products/cdk/overview"&gt;Red Hat Container Development Kit&lt;/a&gt; (CDK) for OpenShift 3.x.&lt;/p&gt; &lt;h2&gt;.NET Core on each platform&lt;/h2&gt; &lt;p&gt;Now, let&amp;#8217;s take a look at how to install .NET Core onto each Red Hat platform.&lt;/p&gt; &lt;h3&gt;.NET Core on Fedora&lt;/h3&gt; &lt;p&gt;.NET Core on Fedora is built by the &lt;a href="https://fedoraproject.org/wiki/SIGs/DotNet" target="_blank" rel="noopener noreferrer"&gt;Fedora .NET Special Interest Group&lt;/a&gt; (SIG). Because .NET Core doesn’t meet the Fedora packaging guidelines, it is distributed from a separate repository.&lt;/p&gt; &lt;p&gt;To install .NET Core on Fedora, you need to enable the &lt;code&gt;copr&lt;/code&gt; repository and install the &lt;code&gt;sdk&lt;/code&gt; package:&lt;/p&gt; &lt;pre&gt;$ sudo dnf copr enable @dotnet-sig/dotnet $ sudo dnf install dotnet-sdk-2.1 &lt;/pre&gt; &lt;p&gt;When possible, the SIG also builds preview versions of .NET Core. These preview versions are distributed from a separate repository:&lt;/p&gt; &lt;pre&gt;$ sudo dnf copr enable @dotnet-sig/dotnet-preview $ sudo dnf install dotnet-sdk-3.1 &lt;/pre&gt; &lt;p&gt;For more information about running .NET Core on Fedora, see the &lt;a href="https://developer.fedoraproject.org/tech/languages/csharp/dotnet-installation.html" target="_blank" rel="noopener noreferrer"&gt;Fedora .NET documentation&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;.NET Core on Red Hat Enterprise Linux 7 and CentOS 7&lt;/h3&gt; &lt;p&gt;On Red Hat Enterprise Linux 7 and CentOS 7, .NET Core versions are packaged into their own software collection (SCLs). This method of packaging allows .NET Core to include libraries that are newer than those provided by the base OS.&lt;/p&gt; &lt;p&gt;To install .NET Core on Red Hat Enterprise Linux, the machine needs to be registered with the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_subscription_management/1/html/quick_registration_for_rhel/registering-machine-ui" target="_blank" rel="noopener noreferrer"&gt;Red Hat subscription management system&lt;/a&gt;. Depending on the OS flavor (e.g., Server, Workstation, or HPC Compute node), you need to enable the proper .NET Core repository:&lt;/p&gt; &lt;pre&gt;$ sudo subscription-manager repos --enable=rhel-7-server-dotnet-rpms $ sudo subscription-manager repos --enable=rhel-7-workstation-dotnet-rpms $ sudo subscription-manager repos --enable=rhel-7-hpc-node-dotnet-rpms &lt;/pre&gt; &lt;p&gt;Next, the SCL tooling needs to be installed:&lt;/p&gt; &lt;pre&gt;$ sudo yum install scl-utils &lt;/pre&gt; &lt;p&gt;Now we can install a specific version of .NET Core:&lt;/p&gt; &lt;pre&gt;$ sudo yum install rh-dotnet21 -y &lt;/pre&gt; &lt;p&gt;To use the .NET Core SCL, we first need to enable it. For example, we can run &lt;code&gt;bash&lt;/code&gt; in the SCL by running:&lt;/p&gt; &lt;pre&gt;$ scl enable rh-dotnet30 bash &lt;/pre&gt; &lt;p&gt;For more information about running .NET Core on Red Hat Enterprise Linux 7, see the &lt;a href="https://access.redhat.com/documentation/en-us/net_core" target="_blank" rel="noopener noreferrer"&gt;.NET Core Getting Started Guides&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;.NET Core on Red Hat Enterprise Linux 8/CentOS 8&lt;/h3&gt; &lt;p&gt;On &lt;a href="https://developers.redhat.com/blog/2019/05/07/red-hat-enterprise-linux-8-now-generally-available/"&gt;the newer RHEL 8&lt;/a&gt;, .NET Core is included in the AppStream repositories, which are enabled by default. A version of .NET Core can be installed by running:&lt;/p&gt; &lt;pre&gt;$ sudo dnf install dotnet-sdk-2.1 &lt;/pre&gt; &lt;p&gt;For more information about running .NET Core on Red Hat Enterprise Linux 8, see the &lt;a href="https://access.redhat.com/documentation/en-us/net_core" target="_blank" rel="noopener noreferrer"&gt;.NET Core Getting Started Guides&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;.NET Core in containers&lt;/h3&gt; &lt;p&gt;Two images are provided per the different .NET Core versions: a runtime image that contains everything necessary to run a .NET Core application, and an SDK image that contains the runtime plus the tooling needed to build applications.&lt;/p&gt; &lt;p&gt;Table 1 shows the names of the images for .NET Core 2.1. For other versions, just change the version numbers in the name.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;Table 1: .NET Core images for version 2.1.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;Base image&lt;/th&gt; &lt;th&gt;SDK/runtime image&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;rhel7&lt;/code&gt;&lt;/td&gt; &lt;td&gt;registry.redhat.io/dotnet/dotnet-21-rhel7:2.1&lt;br /&gt; registry.redhat.io/dotnet/dotnet-21-runtime-rhel7:2.1&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;centos7&lt;/code&gt;&lt;/td&gt; &lt;td&gt;registry.centos.org/dotnet/dotnet-21-centos7:latest&lt;br /&gt; registry.centos.org/dotnet/dotnet-21-runtime-centos7:latest&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;ubi8&lt;/code&gt;&lt;/td&gt; &lt;td&gt;registry.access.redhat.com/ubi8/dotnet-21:2.1&lt;br /&gt; registry.access.redhat.com/ubi8/dotnet-21-runtime:2.1&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; Depending on the version, an image might not (yet) be available for a specific base. For example, CentOS images are made available by the CentOS community after Red Hat Enterprise Linux images are created by Red Hat.&lt;/p&gt; &lt;p&gt;The following example prints out the SDK version that is available in the .NET Core 2.1 &lt;code&gt;ubi8&lt;/code&gt; image:&lt;/p&gt; &lt;pre&gt;$ podman run registry.access.redhat.com/ubi8/dotnet-21:2.1 dotnet --version 2.1.509 &lt;/pre&gt; &lt;p&gt;For more information about the .NET Core images, see the &lt;a href="https://github.com/redhat-developer/s2i-dotnetcore" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;s2i-dotnetcore&lt;/code&gt; GitHub repo&lt;/a&gt;, and the &lt;a href="https://access.redhat.com/documentation/en-us/net_core" target="_blank" rel="noopener noreferrer"&gt;.NET Core Getting Started Guides&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;.NET Core on OpenShift&lt;/h3&gt; &lt;p&gt;The .NET Core images provide an environment for running and building .NET Core applications. They are also compatible with OpenShift’s &lt;a href="https://docs.openshift.com/container-platform/4.2/builds/build-strategies.html#build-strategy-s2i_build-strategies" target="_blank" rel="noopener noreferrer"&gt;source-to-image&lt;/a&gt; (S2I) build strategy. This factor means that the OpenShift container platform can build a .NET Core application from source.&lt;/p&gt; &lt;p&gt;.NET images are imported in OpenShift using the OpenShift CLI client (&lt;code&gt;oc&lt;/code&gt;) with an image stream definition file from the &lt;a href="https://github.com/redhat-developer/s2i-dotnetcore" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;s2i-dotnetcore&lt;/code&gt; GitHub repo&lt;/a&gt;. The file differs depending on the base image, as shown in Table 2.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;Table 2: .NET Core image stream definitions by base image.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;th&gt;Base image&lt;/th&gt; &lt;th&gt;Image stream definition&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;rhel7&lt;/code&gt;&lt;/td&gt; &lt;td&gt;https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore/master/dotnet_imagestreams.json&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;centos7&lt;/code&gt;&lt;/td&gt; &lt;td&gt;https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore/master/dotnet_imagestreams_centos.json&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;code&gt;ubi8&lt;/code&gt;&lt;/td&gt; &lt;td&gt;https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore/master/dotnet_imagestreams_rhel8.json&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Retrieving the Red Hat Enterprise Linux 7 images requires authentication. &lt;a href="https://access.redhat.com/articles/3399531" target="_blank" rel="noopener noreferrer"&gt;Registry Authentication&lt;/a&gt; describes how you can set up the pull secret.&lt;/p&gt; &lt;p&gt;The image streams can be imported using &lt;code&gt;oc&lt;/code&gt;. For example, to import the &lt;code&gt;ubi8&lt;/code&gt;-based images, run:&lt;/p&gt; &lt;pre&gt;$ oc create -f https://raw.githubusercontent.com/redhat-developer/s2i-dotnetcore/master/dotnet_imagestreams_rhel8.json &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; If there are already image streams present for .NET Core, you must use &lt;code&gt;replace&lt;/code&gt; instead of &lt;code&gt;create&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;s2i-dotnetcore&lt;/code&gt; repository includes a script for installing these image streams on Windows, Linux, and macOS. See &lt;a href="https://github.com/redhat-developer/s2i-dotnetcore#installing" target="_blank" rel="noopener noreferrer"&gt;Installing&lt;/a&gt; for more information. This script can also create the pull secret needed for pulling the Red Hat Enterprise Linux 7 images.&lt;/p&gt; &lt;p&gt;Once the image streams are installed, OpenShift can directly build and deploy an application from a Git repo, for example:&lt;/p&gt; &lt;pre&gt;$ oc new-app dotnet:3.1~https://github.com/redhat-developer/s2i-dotnetcore-ex#dotnetcore-3.1 --context-dir=app &lt;/pre&gt; &lt;p&gt;For more information about using .NET Core on OpenShift, see the corresponding chapter in the &lt;a href="https://access.redhat.com/documentation/en-us/net_core" target="_blank" rel="noopener noreferrer"&gt;.NET Core Getting Started Guides&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you got an overview of the Red Hat platforms that support .NET Core, and how to install .NET Core on each of them.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#38;linkname=.NET%20Core%20on%20Red%20Hat%20platforms" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F17%2Fnet-core-on-red-hat-platforms%2F&amp;#038;title=.NET%20Core%20on%20Red%20Hat%20platforms" data-a2a-url="https://developers.redhat.com/blog/2020/01/17/net-core-on-red-hat-platforms/" data-a2a-title=".NET Core on Red Hat platforms"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/17/net-core-on-red-hat-platforms/"&gt;.NET Core on Red Hat platforms&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/4tM1-disMJk" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;In this article, we look at the various ways .NET Core is made available on Red Hat platforms. We start with an overview of the available platforms, and then show how to install .NET Core on each of them. Platform overview Let&amp;#8217;s start with the overview. If you are familiar with these platforms already, you [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/17/net-core-on-red-hat-platforms/"&gt;.NET Core on Red Hat platforms&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">671917</post-id><dc:creator>Tom Deseyn</dc:creator><dc:date>2020-01-17T08:00:13Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/17/net-core-on-red-hat-platforms/</feedburner:origLink></entry><entry><title>New and improved Topology view for OpenShift 4.3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/BubZptsgyL4/" /><category term="Uncategorized" /><author><name>Steve Speicher</name></author><id>https://developers.redhat.com/blog/?p=673847</id><updated>2020-01-16T08:00:47Z</updated><published>2020-01-16T08:00:47Z</published><content type="html">&lt;p&gt;The Topology view in the &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; console’s Developer perspective is a thoughtfully designed interface that provides a visual representation of an application&amp;#8217;s structure. This view helps developers clearly identify one resource type from another, as well as understand the overall communication dynamics within the application. Launched with the 4.2 release of OpenShift, the Topology view has already earned a spotlight in the cloud-native application development arena. The constant feedback cycles and regular follow-ups on the ongoing trends in the developer community have helped to shape up a great experience in the upcoming release. This article focuses on a few showstopper features in the Topology view that were added for OpenShift 4.3.&lt;/p&gt; &lt;h2 id="wPuaAhW"&gt;&lt;b&gt;Toggle between the List view and the Graph view&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;To address a frequent ask from the user community, the Topology view now comes with a toggle button to quickly switch between the List view and the Graph view for a given project, as shown in Figure 1. While the Graph view comes in handy in use cases requiring cognizance of the role played by individual components in the application architecture, List views can be helpful for more data-focused and investigative tasks. The introduction of this toggle would enable seamless navigation through views irrespective of the contrast in use cases.&lt;/p&gt; &lt;div style="width: 657px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh5.googleusercontent.com/NAkFqJMeXwdmDwxD3uvu3ZLMhrwaAK9YIVrfU_gLz0BZ6AW42YR_WXTj556BsmxnCOBBM_YtUFqvlBHPy5GqDy0bNLHCRcqIUn5-i_rZNBdQ-gMUITeBxPgrlfvDgqYrfiJR9LfA" alt="Red Hat OpenShift Topology view toggling between the List and Graph view." width="647" height="352" /&gt;&lt;p class="wp-caption-text"&gt;Figure 1: Toggle between the List and Graph view.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Choose components through the contextual actions menu&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The Topology view offers an elaborate list of components available as a part of the graph, as shown in Figure 2. There are various resource types, connectors, groupings, and items such as event sources, each of which supports a different set of actions in context. Users can access this exclusive menu for each listed item by performing a right-click over them, which further opens a drop-down list with all available actions. Also, users can click anywhere outside the menu to make it disappear from the view.&lt;/p&gt; &lt;div style="width: 663px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh4.googleusercontent.com/mO9phpP7Uns9uIKD1XgGiCdgqUqCpzzW0Azn5ttGJCjcHmeAzIeJdNQZPx4mCoL4OGqGj7IBaT7fM01xOCW_Mq2SdUpMhr3A3zOaMkc6" alt="Red Hat OpenShift Graph view components." width="653" height="361" /&gt;&lt;p class="wp-caption-text"&gt;Figure 2: Access many components through Topology&amp;#8217;s Graph view.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Create a binding between resources&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The Topology view allows you to create a connection between any pair of resources by dragging a handle from the origin node(s) and dropping it over a target node, as shown in Figure 3. This capability reduces the cognitive load on developers by providing a smart assessment of whether an &lt;a href="https://developers.redhat.com/blog/2019/12/19/introducing-the-service-binding-operator/"&gt;Operator-managed backing service&lt;/a&gt; is available for creating the intended binding. In the absence of an Operator-managed backing service, an annotation-based connection is created.&lt;/p&gt; &lt;div style="width: 421px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh6.googleusercontent.com/HL9eoZYlWtcUsCQRlpYITAvwFFeOk5uAls7NREnAmf9wC_dXo0x7pyD9UtBmZUB9w2cyEB_TsWpKPYq_bvv_tit8Q6B5ayBLEtf4wnkicadathnwji9znoskPGAJ6ow1ySzIQ7JM" alt="Creating a connection between a pair of resources in OpenShift by dragging a handle from an origin node to the target node." width="411" height="343" /&gt;&lt;p class="wp-caption-text"&gt;Figure 3: Create a connection between resources.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Visualize &lt;/b&gt;&lt;b&gt;pod transitions in r&lt;/b&gt;&lt;b&gt;eal time&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The Topology view in 4.3 provides convenient and up front access to scale up/down and increase/decrease your pod count via the side panel. Similarly, users can also start rollout or recreate pods for a given node from the contextual menu (accessed through a right-click or from the &lt;strong&gt;Actions&lt;/strong&gt; button on the side panel). Upon performing the associated interaction from the side panel, users see a real-time visualization of the transitions that the pods go through, as shown in Figure 4.&lt;/p&gt; &lt;div style="width: 542px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh3.googleusercontent.com/rQsLdXkMPErb2orJW3dIEh7YvU-V8tPODmFppHAiLy-a3aescqr8fD8WAMe5NW1UqGGTJubbbszNRBNsAuvH2g8SIe4FNTBZFfOCKnsz" alt="Adjusting pod settings and view pod transitions in real time through OpenShift's Topology view." width="532" height="279" /&gt;&lt;p class="wp-caption-text"&gt;Figure 4: Adjust pod settings and view pod transitions in real time.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Delete an application&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The Topology view now supports deleting an application from the Graph view. By invoking the contextual menu for the given application grouping—either by performing a right-click or through the side panel—users can access the &lt;strong&gt;Delete&lt;/strong&gt; action, as shown in Figure 5. Upon confirming this action, the application group (comprising of components with the associated label, as defined by the Kubernetes-recommended labels) is deleted.&lt;/p&gt; &lt;div style="width: 643px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh3.googleusercontent.com/HNX3Osm5iDIaVi2hEQS8kPfAj9LJ5uKmtIkS3Ooa_TAMcMVn2JGA-eqyqvhYoGDce6G_RYCmAkMY0dX30DGVMa9tMdwUSjLF61HQTMRy88n-X1FW7hOym0EF0qx9R9On36k1mB51" alt="Deleting an application in OpenShift's Topology Graph view." width="633" height="351" /&gt;&lt;p class="wp-caption-text"&gt;Figure 5: Delete an application through the Topology Graph view.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;Visualize the event sources sink &lt;/b&gt;&lt;/h2&gt; &lt;p&gt;The Topology view shows elements from Knative Eventing—namely event sources, which visually provide quick insights for developers into which event sources will trigger their application, as shown in Figure 6.&lt;/p&gt; &lt;div style="width: 387px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh6.googleusercontent.com/n74o1Fw0kiWxOZeoeLJbB7X01Kh7ar6Dkncctyvm9JN8SNNGrOggeBCvM-Uwp8JygYMqbsqjiek5nCYR9FflIg6m1NXf0qUt5UijPYEL-_eoRzOwQPmW0g7C6hDwmeZ-dmi7vVwY" alt="Viewing Knative event sources in the OpenShift Topology view." width="377" height="227" /&gt;&lt;p class="wp-caption-text"&gt;Figure 6: View Knative event sources in the Topology view.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;&lt;b&gt;View Knative services and associated revisions&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Users can now view Knative services and their associated Revisions and Deployments in the Topology view. The revisions in a service that are in the active traffic block are displayed as a group within the Topology view, along with the information on their traffic consumption, as shown in Figure 7.&lt;/p&gt; &lt;div style="width: 517px" class="wp-caption aligncenter"&gt;&lt;img class="HiaYvf-SmKAyb" src="https://lh4.googleusercontent.com/-Ce0iho51vctKH1UUPSneCo2KM1shh3mDN6Bs-gtHGuq2ncG7gkSpldQoKwBbQqfuMVgx1xuQYXdlubxsHkUZbQWiCpYeOoVbDRgHlS9GnA7XYaTzGmDeDjLJLLuBCt-8AIYkyo7" alt="View Knative service Revisions and Deployments in the OpenShift Topology view." width="507" height="356" /&gt;&lt;p class="wp-caption-text"&gt;Figure 7: View Knative service Revisions and Deployments in the Topology view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;With the continuous evolution of Kubernetes-related technology and the introduction of new practices and integrations, OpenShift is constantly updated to reflect this progression.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Learn more&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;Interested in learning more about application development with OpenShift? Check out our resources on &lt;a href="http://developers.redhat.com/openshift"&gt;application development in OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;&lt;b&gt;Provide feedback&lt;/b&gt;&lt;/h2&gt; &lt;p&gt;To provide feedback, either join our &lt;a href="https://groups.google.com/forum/#!forum/openshift-dev-users" target="_blank" rel="noopener noreferrer"&gt;OpenShift Developer Experience Google Group&lt;/a&gt;, where you can participate in discussions or attend our Office Hours Feedback session, or drop us an &lt;a href="mailto:openshift-ux@redhat.com" target="_blank" rel="noopener noreferrer"&gt;email&lt;/a&gt; with your comments about the OpenShift Console user experience anytime.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#38;linkname=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F16%2Fnew-and-improved-topology-view-for-openshift-4-3%2F&amp;#038;title=New%20and%20improved%20Topology%20view%20for%20OpenShift%204.3" data-a2a-url="https://developers.redhat.com/blog/2020/01/16/new-and-improved-topology-view-for-openshift-4-3/" data-a2a-title="New and improved Topology view for OpenShift 4.3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/16/new-and-improved-topology-view-for-openshift-4-3/"&gt;New and improved Topology view for OpenShift 4.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/BubZptsgyL4" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The Topology view in the Red Hat OpenShift console’s Developer perspective is a thoughtfully designed interface that provides a visual representation of an application&amp;#8217;s structure. This view helps developers clearly identify one resource type from another, as well as understand the overall communication dynamics within the application. Launched with the 4.2 release of OpenShift, the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/16/new-and-improved-topology-view-for-openshift-4-3/"&gt;New and improved Topology view for OpenShift 4.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">673847</post-id><dc:creator>Steve Speicher</dc:creator><dc:date>2020-01-16T08:00:47Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/16/new-and-improved-topology-view-for-openshift-4-3/</feedburner:origLink></entry><entry><title>Day in the Life with Decisions, Optimization, and Process Automation</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/adXktVTj9sg/day-in-the-life-with-decisions-optimization-process-automation.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="Business Resource Planner" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="event" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><category term="workshops" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-day_in_the_life_with_decisions_optimization_and_process_automation</id><updated>2020-01-16T08:30:41Z</updated><published>2020-01-16T06:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a ecisionoptimizationautomationworkshop="" href="https://www.blogger.com/null" https:="" imageanchor="1" red.ht="" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" target="_blank"&gt;&lt;img alt="workshopo" border="0" data-original-height="417" data-original-width="626" height="133" src="https://1.bp.blogspot.com/-3gjy0QzISb0/XiAe1HOAieI/AAAAAAAABnM/5XPh4Vp9xK0DSArJ4Z9r-P6eOeB_tI7YwCLcBGAsYHQ/s200/hands-on-keyboard.jpg" title="" width="200" /&gt;&lt;/a&gt;On Friday, 4 February 2020 we'll be in Dublin, Ireland to share &lt;a href="https://red.ht/DecisionOptimizationAutomationWorkshop" target="_blank"&gt;a day long workshop&lt;/a&gt; with expert and evangelist &lt;a href="https://twitter.com/duncandoyle?lang=en" target="_blank"&gt;Duncan Doyle&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;You'll experience all the developer tooling you need to get hands on with business decisions, AI driven optimization, and process automaton.&lt;br /&gt;&lt;br /&gt;Would you like to join us?&lt;br /&gt;&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;We call this experience &lt;a href="https://red.ht/DecisionOptimizationAutomationWorkshop" target="_blank"&gt;a day in the life with decisions, optimization, and process automation&lt;/a&gt; and you can register to attend by following this link.&lt;br /&gt;&lt;br /&gt;You'll get face time with experts in these open source technologies and learn about decision management, planning optimization driven by open source AI technologies, and how to effectively implement process automation in your development projects.&lt;br /&gt;&lt;br /&gt;&lt;div align="center"&gt;&lt;blockquote class="twitter-tweet"&gt;&lt;div dir="ltr" lang="en"&gt;Ready to get hands-on with the experts? Join &lt;a href="https://twitter.com/DuncanDoyle?ref_src=twsrc%5Etfw"&gt;@DuncanDoyle&lt;/a&gt; and myself in &lt;a href="https://twitter.com/hashtag/Dublin?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#Dublin&lt;/a&gt; for an all day workshop for developers. It's a day in the life with decisions, optimization, and &lt;a href="https://twitter.com/hashtag/process?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#process&lt;/a&gt; &lt;a href="https://twitter.com/hashtag/automation?src=hash&amp;amp;ref_src=twsrc%5Etfw"&gt;#automation&lt;/a&gt;. &lt;a href="https://t.co/ytICdEgEqa"&gt;https://t.co/ytICdEgEqa&lt;/a&gt; &lt;a href="https://twitter.com/keith_lynch?ref_src=twsrc%5Etfw"&gt;@keith_lynch&lt;/a&gt; &lt;a href="https://twitter.com/RedHatEvents?ref_src=twsrc%5Etfw"&gt;@RedHatEvents&lt;/a&gt; &lt;a href="https://twitter.com/RedHatUK?ref_src=twsrc%5Etfw"&gt;@RedHatUK&lt;/a&gt; &lt;a href="https://t.co/wXsDwyLzCl"&gt;pic.twitter.com/wXsDwyLzCl&lt;/a&gt;&lt;/div&gt;— Eric D. Schabell (@ericschabell) &lt;a href="https://twitter.com/ericschabell/status/1217487580612169731?ref_src=twsrc%5Etfw"&gt;January 15, 2020&lt;/a&gt;&lt;/blockquote&gt;&lt;script async="" charset="utf-8" src="https://platform.twitter.com/widgets.js"&gt;&lt;/script&gt; &lt;/div&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Overview&lt;/h3&gt;&lt;div style="text-align: left;"&gt;Decisions, planning, and processes are core to every organization and this unique day provides an introduction and hands-on experience on OpenShift Container Platform. Learn how to tackle complex decisions, solve planning problems leverage AI techniques, and implement organizational processes leveraging the power of open technologies.&lt;br /&gt;&lt;br /&gt;Attendees will learn how to effectively install, implement, deploy and manage applications using Red Hat Decision Manager, Red Hat Business Optimizer, and Red Hat Process Automation Manager on OpenShift Container platform.&lt;/div&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;What you'll learn&lt;/h3&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;How to create models of business processes and decisions using standard notations such as BPMN&lt;/li&gt;&lt;li&gt;How to convert models into fully working applications that directly encode business expertise&lt;/li&gt;&lt;li&gt;How these new applications can be deployed, managed and scaled across hybrid clouds in OpenShift&lt;/li&gt;&lt;li&gt;How to use decision standards and implement a deterministic vacation allocation application&lt;/li&gt;&lt;li&gt;How to identify planning problems, create A.I. algorithmic solvers, and write constraints for a cloud infrastructure balancing problem.&lt;/li&gt;&lt;/ul&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;On top of all of this, you'll have a full day to interact with experts who've implemented and worked with customers who've deployed applications around the globe using these open technologies.&lt;/div&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: left;"&gt;Don't miss this opportunity and we'll see you in Dublin!&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZIl7osJRr9I:uQmJvBNjKxI:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZIl7osJRr9I:uQmJvBNjKxI:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZIl7osJRr9I:uQmJvBNjKxI:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=ZIl7osJRr9I:uQmJvBNjKxI:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=ZIl7osJRr9I:uQmJvBNjKxI:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/ZIl7osJRr9I" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/adXktVTj9sg" height="1" width="1" alt=""/&gt;</content><summary>On Friday, 4 February 2020 we'll be in Dublin, Ireland to share a day long workshop with expert and evangelist Duncan Doyle. You'll experience all the developer tooling you need to get hands on with business decisions, AI driven optimization, and process automaton. Would you like to join us? We call this experience a day in the life with decisions, optimization, and process automation and you can ...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-01-16T06:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/ZIl7osJRr9I/day-in-the-life-with-decisions-optimization-process-automation.html</feedburner:origLink></entry><entry><title>What’s new in the OpenShift 4.3 console developer experience</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3wCRqyvpZrQ/" /><category term="Containers" /><category term="Developer Tools" /><category term="DevOps" /><category term="Operator" /><category term="OpenShift 4.3" /><category term="pipelines" /><category term="prometheus" /><category term="Red Hat OpenShift Container Platform" /><category term="Tekton" /><author><name>Steve Speicher</name></author><id>https://developers.redhat.com/blog/?p=673817</id><updated>2020-01-15T14:57:13Z</updated><published>2020-01-15T14:57:13Z</published><content type="html">&lt;p&gt;The developer experience is significantly improved in the &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; 4.3 web console. If you have used the Developer perspective, which was introduced in OpenShift 4.2 Console, you are probably familiar with our streamlined user flows for deploying applications, the new Topology view, and the enhanced experience around &lt;a href="https://developers.redhat.com/blog/2020/01/08/the-new-tekton-pipelines-extension-for-visual-studio-code/"&gt;OpenShift Pipelines powered by Tekton&lt;/a&gt; and OpenShift Serverless powered by Knative. This release continues to improve upon the features that were introduced in 4.2 and introduces new flows and features for the developer.&lt;/p&gt; &lt;h2&gt;Deploying applications&lt;/h2&gt; &lt;p&gt;The Developer perspective offers several built-in ways to streamline the process of deploying applications, services, and databases. In 4.3, you’ll find the following improvements to these user flows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Support for the deployment of an image stream from an internal registry.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674417 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-1024x476.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream.png" alt="" width="1600" height="743" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-768x357.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-image-stream-1024x476.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Builder image detection in the Import from Git user flow.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674437 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png" alt="" width="512" height="258" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-git-300x151.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Deployment options between Kubernetes Deployments (default), OpenShift DeploymentConfigs, and Knative service (tech preview). (This option gives the developer easy ways to switch between deployment types without having to learn YAML or other templating solutions.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png" alt="" width="512" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-deployment-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;Topology view&lt;/h2&gt; &lt;p&gt;The Topology view offers significant usability improvements and new flows for 4.3:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Switch between a graphical and list presentation of your project.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-1024x577.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology.png" alt="" width="1600" height="902" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-768x433.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-1024x577.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674467 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-1024x575.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2.png" alt="" width="1600" height="898" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-300x168.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-768x431.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-topology-2-1024x575.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Access the ability to scale up/down and increase/decrease your pod count easily via the side panel or the associated detail page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674477 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-1024x580.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling.png" alt="" width="1600" height="906" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-300x170.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-768x435.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-scaling-1024x580.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;View real-time visualization of rolling and recreate rollouts on the component in Topology, as well as in the associated side panel.&lt;/li&gt; &lt;li&gt;Delete an application, which is accomplished by deleting all components with the associated label, as defined by the Kubernetes-recommended labels.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674507 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png" alt="" width="548" height="310" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-delete1-300x169.png 300w" sizes="(max-width: 548px) 100vw, 548px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Access context menus are via right-click as well as in the Actions menu in the associated side panel.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-developer-context2-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;h2&gt;Miscellaneous&lt;/h2&gt; &lt;p&gt;Additional improvements let you:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Click the newly added Project details navigation item to access a new Project dashboard and delete your Project.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674537 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-1024x575.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project.png" alt="" width="1600" height="899" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project.png 1600w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-768x432.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-project-1024x575.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Share your projects easily with other users through a simplified view of Project membership if you are a developer with the appropriate access.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674547 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-membership.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-membership.png" alt="" width="565" height="311" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Troubleshoot problems with your applications by running Prometheus Query Language (PromQL) queries on your Project and examining the metrics visualized on a plot. This Tech Preview feature is available on the Metrics page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674557 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-troubleshoot-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;h2&gt;Binding&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://github.com/operator-backing-service-samples/postgresql-operator" target="_blank" rel="noopener noreferrer"&gt;Service Binding Operator&lt;/a&gt; enables application developers to more easily bind applications together with Operator-managed backing services such as databases, without having to manually configure secrets, ConfigMaps, etc. In Topology in 4.3, you can quickly and easily create a binding between two components.&lt;/p&gt; &lt;h3&gt;OpenShift Pipelines&lt;/h3&gt; &lt;p&gt;The OpenShift Pipeline Operator enhances the OpenShift console with developer CI/CD solutions that leverage the Tekton project. In 4.3, you’ll see the following improvements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Users can enable CI/build Pipelines to an application.&lt;/li&gt; &lt;li&gt;When a pipeline is associated with a component in Topology, the user will be able to view the association as well as preview the Pipeline&amp;#8217;s status in the Topology view.&lt;/li&gt; &lt;li&gt;The Logs tab of a Pipeline run provides the ability to view the task logs in real time. Users now have the ability to download a Pipeline&amp;#8217;s task logs.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674567 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png" alt="" width="512" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-logs-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;h2&gt;Red Hat OpenShift Serverless&lt;/h2&gt; &lt;p&gt;In 4.3, improvements to the Tech Preview for &lt;a href="https://www.openshift.com/learn/topics/serverless" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift Serverless&lt;/a&gt; features include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Visualizing Knative Services as a group, which allows the user to review all revisions in the traffic block visually in the Topology view.&lt;/li&gt; &lt;li&gt;Letting users modify the traffic distribution among the revisions of a Knative service.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674577 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png" alt="" width="512" height="288" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless.png 512w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-300x169.png 300w" sizes="(max-width: 512px) 100vw, 512px" /&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Showing elements from Knative Eventing, namely event sources, which provides developers with quick insight into which event sources will trigger their application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" size-full wp-image-674587 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png" alt="" width="377" height="227" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources.png 377w, https://developers.redhat.com/blog/wp-content/uploads/2020/01/openshift-serverless-event-sources-300x181.png 300w" sizes="(max-width: 377px) 100vw, 377px" /&gt;&lt;/p&gt; &lt;h2&gt;Learn more&lt;/h2&gt; &lt;p&gt;Interested in learning more about application development with OpenShift? Check out these Red Hat resources for &lt;a href="http://developers.redhat.com/openshift"&gt;application development on OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Provide feedback&lt;/h2&gt; &lt;p&gt;Join our &lt;a href="https://groups.google.com/forum/#!forum/openshift-dev-users" target="_blank" rel="noopener noreferrer"&gt;OpenShift Developer Experience Google Group&lt;/a&gt;, participate in discussions, or attend our Office Hours Feedback session. Or, drop us an &lt;a href="mailto:openshift-ux@redhat.com" target="_blank" rel="noopener noreferrer"&gt;email&lt;/a&gt; with your comments about the OpenShift Console user experience.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#38;linkname=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Fwhats-new-in-the-openshift-4-3-console-developer-experience%2F&amp;#038;title=What%E2%80%99s%20new%20in%20the%20OpenShift%204.3%20console%20developer%20experience" data-a2a-url="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/" data-a2a-title="What’s new in the OpenShift 4.3 console developer experience"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/"&gt;What’s new in the OpenShift 4.3 console developer experience&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3wCRqyvpZrQ" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The developer experience is significantly improved in the Red Hat OpenShift 4.3 web console. If you have used the Developer perspective, which was introduced in OpenShift 4.2 Console, you are probably familiar with our streamlined user flows for deploying applications, the new Topology view, and the enhanced experience around OpenShift Pipelines powered by Tekton and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/"&gt;What’s new in the OpenShift 4.3 console developer experience&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">673817</post-id><dc:creator>Steve Speicher</dc:creator><dc:date>2020-01-15T14:57:13Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/15/whats-new-in-the-openshift-4-3-console-developer-experience/</feedburner:origLink></entry><entry><title>JBossWS 5.4.0.FInal is released !</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZIz8N39hz7w/jbossws-540final-is-released.html" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_jbossws" scheme="searchisko:content:tags" /><author><name>jimma</name></author><id>searchisko:content:id:jbossorg_blog-jbossws_5_4_0_final_is_released</id><updated>2020-01-15T09:41:51Z</updated><published>2020-01-15T09:41:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br class="Apple-interchange-newline" /&gt;I am pleased to annouce JBossWS 5.4.0 Final is out. In this release we upgraded many components as usual and brings Elytron client configuration support. Apache CXF is now upgraded to 3.3.4 and more issues has been fixed in this release. For more detailed info and full list of issues resolved, please check&amp;nbsp;&lt;a href="https://issues.redhat.com/secure/ReleaseNote.jspa?version=12341950&amp;amp;projectId=12310050"&gt;release notes.&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;If you have any problem and want to send feedback for this new release, please post at&lt;a href="https://developer.jboss.org/en/jbossws/cxf"&gt;&amp;nbsp;jbossws forum&lt;/a&gt;&amp;nbsp;or file issues in JIRA at:&amp;nbsp;&lt;a href="https://issues.jboss.org/projects/JBWS"&gt;https://issues.jboss.org/projects/JBWS&lt;/a&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZIz8N39hz7w" height="1" width="1" alt=""/&gt;</content><summary>I am pleased to annouce JBossWS 5.4.0 Final is out. In this release we upgraded many components as usual and brings Elytron client configuration support. Apache CXF is now upgraded to 3.3.4 and more issues has been fixed in this release. For more detailed info and full list of issues resolved, please check release notes. If you have any problem and want to send feedback for this new release, pleas...</summary><dc:creator>jimma</dc:creator><dc:date>2020-01-15T09:41:00Z</dc:date><feedburner:origLink>http://jbossws.blogspot.com/2020/01/jbossws-540final-is-released.html</feedburner:origLink></entry><entry><title>Installing debugging tools into a Red Hat OpenShift container with oc-inject</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VuD5C7RO2W0/" /><category term="Containers" /><category term="DevOps" /><category term="OpenShift" /><category term="CodeReady Containers" /><category term="debugging" /><category term="openshift" /><author><name>Serhei Makarov</name></author><id>https://developers.redhat.com/blog/?p=663407</id><updated>2020-01-15T08:00:05Z</updated><published>2020-01-15T08:00:05Z</published><content type="html">&lt;p&gt;A previous article, &lt;a href="https://developers.redhat.com/blog/2020/01/09/debugging-applications-within-red-hat-openshift-containers/"&gt;Debugging applications within Red Hat OpenShift containers,&lt;/a&gt; gives an overview of tools for debugging applications within &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; containers, and existing restrictions on their use. One of the restrictions discussed in that article was an inability to install debugging tool packages into an ordinary, unprivileged container once it was already instantiated. In such a container, debugging tool packages have to be included when the container image is built, because once the container is instantiated, using package installation commands requires elevated privileges that are not available to the ordinary container user.&lt;/p&gt; &lt;p&gt;However, there are important situations where it is desirable to install a debugging tool into an already-instantiated container. In particular, if the resolution of a problem requires access to the temporary state of a long-running containerized application, the usual method of adding debugging tools to the container by rebuilding the container image and restarting the application will destroy that temporary state.&lt;/p&gt; &lt;p&gt;To provide a way to add debugging tools to unprivileged containers, I developed a utility, called &lt;code&gt;oc-inject&lt;/code&gt;, that can temporarily copy a debugging tool into a container. Instead of relying on package management or other privileged operations, &lt;code&gt;oc-inject&lt;/code&gt;’s implementation is based on the existing and well-supported OpenShift operations &lt;code&gt;oc rsync&lt;/code&gt; and &lt;code&gt;oc exec&lt;/code&gt;, which do not require any elevated privileges.&lt;/p&gt; &lt;p&gt;This article describes the current capabilities of the &lt;code&gt;oc-inject&lt;/code&gt; utility, which is available &lt;a href="https://github.com/serhei/oc-inject/" target="_blank" rel="noopener noreferrer"&gt;on GitHub&lt;/a&gt; or &lt;a href="https://copr.fedorainfracloud.org/coprs/serhei/oc-inject/" target="_blank" rel="noopener noreferrer"&gt;via a Fedora COPR repository&lt;/a&gt;. The &lt;code&gt;oc-inject&lt;/code&gt; utility works on any Linux system that includes Python 3, the &lt;code&gt;ldd&lt;/code&gt; utility, and the Red Hat OpenShift command-line tool &lt;code&gt;oc&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;span id="more-663407"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2 id="how-oc-inject-works"&gt;How &lt;code&gt;oc-inject&lt;/code&gt; works&lt;/h2&gt; &lt;p&gt;&lt;code&gt;oc-inject&lt;/code&gt; is a command-line utility that can be invoked from any local Linux system that has been configured to communicate with an OpenShift cluster via the &lt;code&gt;oc&lt;/code&gt; command-line tool. The &lt;code&gt;oc-inject&lt;/code&gt; utility has the following command-line syntax:&lt;/p&gt; &lt;pre&gt;oc-inject &amp;#60;pod_ID&amp;#62; &amp;#60;executable&amp;#62; &lt;/pre&gt; &lt;p&gt;Here, &lt;code&gt;pod_ID&lt;/code&gt; is the name of an OpenShift container, and &lt;code&gt;executable&lt;/code&gt; is the name of an executable on the local system.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;oc-inject&lt;/code&gt; utility installs the specified executable into the container and then runs it. An executable installed by &lt;code&gt;oc-inject&lt;/code&gt; could be a debugging tool or another system utility that would otherwise not be available in the container.&lt;/p&gt; &lt;p&gt;For example, using &lt;code&gt;oc-inject&lt;/code&gt;, we can install and run the &lt;code&gt;htop&lt;/code&gt; utility in order to visualize the CPU and memory usage of processes within the container &lt;code&gt;myapp-rxxrw&lt;/code&gt;(outlined in Figure 1):&lt;/p&gt; &lt;pre&gt;$ oc-inject -it myapp-rxxrw htop &lt;/pre&gt; &lt;div id="attachment_663417" style="width: 547px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-663417" class="wp-image-663417 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final.png" alt="Diagram of oc-inject operation." width="537" height="329" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final.png 537w, https://developers.redhat.com/blog/wp-content/uploads/2019/12/oc-inject-for-blog-final-300x184.png 300w" sizes="(max-width: 537px) 100vw, 537px" /&gt;&lt;p id="caption-attachment-663417" class="wp-caption-text"&gt;Figure 1: The flow of an &lt;code&gt;oc-inject&lt;/code&gt; operation.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;oc-inject&lt;/code&gt; utility operates as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;First, &lt;code&gt;oc-inject&lt;/code&gt; uses the &lt;a href="http://man7.org/linux/man-pages/man1/ldd.1.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;ldd&lt;/code&gt;&lt;/a&gt; utility to identify the set of shared libraries required by the executable.&lt;/li&gt; &lt;li&gt;Second, &lt;code&gt;oc-inject&lt;/code&gt; invokes the OpenShift &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-copying-files.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;oc rsync&lt;/code&gt;&lt;/a&gt; command to copy the executable and the identified shared libraries into a temporary directory within the container.&lt;/li&gt; &lt;li&gt;Finally, &lt;code&gt;oc-inject&lt;/code&gt; invokes the &lt;a href="https://docs.openshift.com/container-platform/4.2/nodes/containers/nodes-containers-remote-commands.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;oc exec&lt;/code&gt;&lt;/a&gt; command to run the executable. In order for the executable to use the shared libraries within the temporary directory, &lt;code&gt;oc-inject&lt;/code&gt; sets the executable’s &lt;code&gt;LD_LIBRARY_PATH&lt;/code&gt; environment variable to this directory.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;It is important to keep in mind that if the executable installed by &lt;code&gt;oc-inject&lt;/code&gt; depends on files other than shared libraries, &lt;code&gt;oc-inject&lt;/code&gt; will not copy these files into the container. This limitation narrows the set of executables that can be installed with &lt;code&gt;oc-inject&lt;/code&gt;. However, in practice, such commonly used debugging tools as &lt;code&gt;gdbserver&lt;/code&gt; and &lt;code&gt;strace&lt;/code&gt; require only shared libraries and can be successfully installed and run using &lt;code&gt;oc-inject&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The examples in the following sections illustrate how the &lt;code&gt;gdbserver&lt;/code&gt; and &lt;code&gt;strace&lt;/code&gt; debugging tools can be installed and used to observe the behavior of a containerized application. The procedures in these examples were tested on an OpenShift 4.2.8 cluster managed with &lt;a href="https://github.com/code-ready/crc" target="_blank" rel="noopener noreferrer"&gt;CodeReady Containers 1.2.0&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="first-example-tracing-system-calls-in-a-postgresql-process-using-strace"&gt;Example 1: Tracing system calls in a PostgreSQL process using &lt;code&gt;strace&lt;/code&gt;&lt;/h2&gt; &lt;ol&gt; &lt;li&gt;Create an OpenShift application based on the &lt;a href="https://github.com/sclorg/rails-ex" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;rails-ex&lt;/code&gt;&lt;/a&gt; application template from the &lt;a href="https://www.softwarecollections.org/" target="_blank" rel="noopener noreferrer"&gt;software-collections.org&lt;/a&gt; repository:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ git clone https://github.com/sclorg/rails-ex $ oc new-app rails-ex/openshift/templates/rails-postgresql.json -p SOURCE_REPOSITORY_URL=https://github.com/sclorg/rails-ex &lt;/pre&gt; &lt;p&gt;This template creates several containers, including a container with a PostgreSQL database.&lt;/p&gt; &lt;ol start="2"&gt; &lt;li&gt;Run &lt;code&gt;oc get pods&lt;/code&gt; and &lt;code&gt;ps -ax&lt;/code&gt;to identify the name of the PostgreSQL container and the PIDs of processes within the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc get pods NAME READY STATUS RESTARTS AGE postgresql-1-deploy 0/1 Completed 0 4m23s postgresql-1-jfg52 1/1 Running 0 4m8s rails-postgresql-example-1-build 0/1 Completed 0 4m24s rails-postgresql-example-1-deploy 0/1 Completed 0 72s rails-postgresql-example-1-gg5hm 1/1 Running 0 26s rails-postgresql-example-1-hook-pre 0/1 Completed 0 63s $ oc exec -it postgresql-1-jfg52 -- ps -ax PID TTY STAT TIME COMMAND 1 ? Ss 0:00 postgres 62 ? Ss 0:00 postgres: logger process 64 ? Ss 0:00 postgres: checkpointer process 65 ? Ss 0:00 postgres: writer process 66 ? Ss 0:00 postgres: wal writer process 67 ? Ss 0:00 postgres: autovacuum launcher process 68 ? Ss 0:00 postgres: stats collector process 69 ? Ss 0:00 postgres: bgworker: logical replication launcher 391 ? Ss 0:00 postgres: userY5Q root 10.128.0.190(39754) idle 414 ? Ss 0:00 postgres: userY5Q root 10.128.0.190(39882) idle 481 pts/0 Rs+ 0:00 ps -ax &lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;We are interested in tracing the system calls made by one of the PostgreSQL worker processes. The output of &lt;code&gt;ps -ax&lt;/code&gt; lists two such processes, with PIDs 391 and 414. For this example, we will trace the process with PID 414. We invoke &lt;code&gt;oc-inject&lt;/code&gt; to install an &lt;code&gt;strace&lt;/code&gt; executable into the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc-inject -it postgresql-1-jfg52 -- strace -p 414 /tmp/oc-inject-af154698/strace: Process 414 attached epoll_wait(3, [{EPOLLIN, {u32=34512144, u64=34512144}}], 1, -1) = 1 recvfrom(11, "Q\0\0\0\rSELECT 1\0", 8192, 0, NULL, NULL) = 14 sendto(10, "\2\0\0\0\230\0\0\0\1@\0\0\1\0\0\0\2\0\0\0\0\0\0\0\0\0\0\0\0\0\0\0"..., 152, 0, NULL, 0) = 152 sendto(11, "T\0\0\0!\0\1?column?\0\0\0\0\0\0\0\0\0\0\27\0\4\377\377\377\377"..., 66, 0, NULL, 0) = 66 recvfrom(11, "P\0\0\0+\0SELECT \"articles\".* FROM \""..., 8192, 0, NULL, NULL) = 81 lseek(15, 0, SEEK_END) = 8192 lseek(16, 0, SEEK_END) = 16384 lseek(15, 0, SEEK_END) = 8192 sendto(11, "1\0\0\0\0042\0\0\0\4T\0\0\0\204\0\5id\0\0\0@\24\0\1\0\0\0\27\0\4"..., 268, 0, NULL, 0) = 268 recvfrom(11, 0xcad700, 8192, 0, NULL, NULL) = -1 EAGAIN (Resource temporarily unavailable) epoll_wait(3, [{EPOLLIN, {u32=34512144, u64=34512144}}], 1, -1) = 1 ... ^C /tmp/oc-inject-af154698/strace: Process 414 detached &amp;#60;detached ...&amp;#62; command terminated with exit code 130 &lt;/pre&gt; &lt;p&gt;Thus, we obtained a trace of interactions between the PostgreSQL process and the underlying operating system.&lt;/p&gt; &lt;h2 id="second-example-tracing-postgresql-internal-behaviour-by-attaching-to-sdt-markers-with-gdbserver"&gt;Example 2: Tracing PostgreSQL&amp;#8217;s internal behavior by attaching to SDT markers with &lt;code&gt;gdbserver&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;In this example, we demonstrate how to collect trace data from a PostgreSQL process. In order to do this, we use statically defined tracing (SDT) markers, which identify various high-level events within the process. The SDT marker for an event has a list of arguments that provide information about the event to a debugging tool.&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&lt;b&gt;Note:&lt;/b&gt; Many applications, libraries, and runtimes provide built-in SDT markers that can be traced by GDB, including the PostgreSQL, MySQL and MariaDB database engines; core system libraries such as &lt;code&gt;glibc&lt;/code&gt;; and language runtimes for Python, Ruby, Java, and Node.js. A more comprehensive list of applications and libraries with SDT markers is maintained on the &lt;a href="https://sourceware.org/systemtap/wiki/" target="_blank" rel="noopener noreferrer"&gt;SystemTap wiki&lt;/a&gt;. In addition to the &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Static-Probe-Points.html" target="_blank" rel="noopener noreferrer"&gt;official GDB documentation&lt;/a&gt;, an earlier &lt;a href="https://blog.sergiodj.net/2012/03/29/gdb-and-systemtap-probes-part-1.html" target="_blank" rel="noopener noreferrer"&gt;blog series&lt;/a&gt; by Sergio Durigan Junior (&lt;a href="https://blog.sergiodj.net/2012/10/27/gdb-and-systemtap-probes-part-2.html" target="_blank" rel="noopener noreferrer"&gt;part 2&lt;/a&gt;, &lt;a href="https://blog.sergiodj.net/2012/11/02/gdb-and-systemtap-probes-part-3.html" target="_blank" rel="noopener noreferrer"&gt;part 3&lt;/a&gt;) gives more information about GDB’s support for tracing SDT markers.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;PostgreSQL’s built-in SDT markers identify various high-level database events. The PostgreSQL documentation gives &lt;a href="https://www.postgresql.org/docs/10/dynamic-trace.html" target="_blank" rel="noopener noreferrer"&gt;a full description of available markers&lt;/a&gt; and associated arguments.&lt;/p&gt; &lt;p&gt;The following steps illustrate how to collect SDT trace data using &lt;code&gt;gdbserver&lt;/code&gt;:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Start a containerized PostgreSQL process following the same procedure as described in Example 1&amp;#8217;s first step.&lt;/li&gt; &lt;li&gt;Start a GDB session outside the container:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ gdb GNU gdb (GDB) Fedora 8.2-6.fc29 Copyright (C) 2018 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &amp;#60;http://gnu.org/licenses/gpl.html&amp;#62; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type "show copying" and "show warranty" for details. (gdb) &lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Invoke &lt;code&gt;oc-inject&lt;/code&gt; to install and run &lt;code&gt;gdbserver&lt;/code&gt; within the container, and instruct the GDB session to connect to the &lt;code&gt;gdbserver&lt;/code&gt;’s standard input and output:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) target extended-remote | oc-inject -i postgresql-1-jfg52 -- gdbserver --multi - Remote debugging using | oc-inject -i postgresql-1-jfg52 -- gdbserver --multi - Remote debugging using stdio (gdb) &lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Instruct the running &lt;code&gt;gdbserver&lt;/code&gt; to attach to the desired PostgreSQL worker process (PID 391 in this case):&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) attach 391 Attaching to process 391 Attached; pid = 391 Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres from remote target... warning: File transfers from remote targets can be slow. Use "set sysroot" to access files locally instead. Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres from remote target... Reading symbols from target:/opt/rh/rh-postgresql10/root/usr/bin/postgres...Reading /opt/rh/rh-postgresql10/root/usr/bin/postgres.debug from remote target... Reading /opt/rh/rh-postgresql10/root/usr/bin/.debug/postgres.debug from remote target... Missing separate debuginfo for target:/opt/rh/rh-postgresql10/root/usr/bin/postgres Try: dnf --enablerepo='*debug*' install /usr/lib/debug/.build-id/14/1c5e620c9ea33d7e9214b6e4d5a4d4519e4a10.debug Reading symbols from .gnu_debugdata for target:/opt/rh/rh-postgresql10/root/usr/bin/postgres...(no debugging symbols found)...done. (no debugging symbols found)...done. ... 0x00007fee94155973 in __select_nocancel () from target:/lib64/libc.so.6 &lt;/pre&gt; &lt;ol start="5"&gt; &lt;li&gt;After attaching to the process, obtain a list of available SDT markers with GDB’s &lt;code&gt;info probes&lt;/code&gt; command:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) info probes ... stap postgresql query__rewrite__start 0x00000000007189fd 0x0000000000cac470 target:/opt/rh/rh-postgresql10/root/usr/bin/postgres stap postgresql query__start 0x0000000000718c45 0x0000000000cac464 target:/opt/rh/rh-postgresql10/root/usr/bin/postgres stap postgresql smgr__md__read__done 0x00000000007142c5 0x0000000000cac42a target:/opt/rh/rh-postgresql10/root/usr/bin/postgres ... &lt;/pre&gt; &lt;ol start="6"&gt; &lt;li&gt;Define a tracepoint that will trigger on the &lt;code&gt;query__start&lt;/code&gt; marker, which identifies the event of the process starting to execute a database query:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) trace -probe-stap query__start Tracepoint 1 at 0x718c45 &lt;/pre&gt; &lt;p&gt;As described in the &lt;a href="https://www.postgresql.org/docs/10/dynamic-trace.html" target="_blank" rel="noopener noreferrer"&gt;PostgreSQL documentation&lt;/a&gt;, the &lt;code&gt;query__start&lt;/code&gt; marker returns the query string through an argument of type &lt;code&gt;char *&lt;/code&gt;. In a GDB session, this argument can be referenced via the identifier &lt;code&gt;$_probe_arg0&lt;/code&gt;.&lt;/p&gt; &lt;ol start="7"&gt; &lt;li&gt;Define the actions we want GDB to take whenever the tracepoint triggers. Let’s say that we want GDB to collect the value of the &lt;code&gt;query__start&lt;/code&gt; SDT marker&amp;#8217;s query string argument. To do so, we must instruct GDB to collect both the value of the argument as well as the memory locations this value points to:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) actions 1 &amp;#62;collect $_probe_arg0 &amp;#62;collect *(unsigned char *)$_probe_arg0@512 &amp;#62;end &lt;/pre&gt; &lt;ol start="8"&gt; &lt;li&gt;Use the &lt;code&gt;tstart&lt;/code&gt; command described in GDB’s documentation on &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Tracepoints.html#Tracepoints" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;tracepoints&lt;/code&gt;&lt;/a&gt; to collect trace data while the program continues running:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) tstart (gdb) continue &amp;#38; &lt;/pre&gt; &lt;ol start="9"&gt; &lt;li&gt;As the program continues to run, GDB will continue to collect trace data. To view the collected data, interrupt the program and use the &lt;code&gt;tfind&lt;/code&gt; command to step through the collected trace data:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;(gdb) interrupt (gdb) tstatus Trace is running on the target. Collected 18 trace frames. Trace buffer has 5229992 bytes of 5242880 bytes free (0% full). Trace will stop if GDB disconnects. Not looking at any trace frame. Trace started at 7393.098048 secs, stopped -111.-534238 secs later. (gdb) tstop (gdb) tfind start Found trace frame 0, tracepoint 1 #0 0x0000000000718c45 in exec_simple_query () (gdb) print/x $_probe_arg0 $1 = 0x1763358 (gdb) tdump Data collected at tracepoint 1, trace frame 0: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "SELECT 1\000\000\000ticles\".* FROM \"articles\"\000\000\000\000CT indrelid, indkey, generate_subscripts(indkey, 1) idx\n", ' ' &amp;#60;repeats 11 times&amp;#62;, "FROM pg_index\n WHERE indrelid = '\"articles\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... (gdb) while ($trace_frame != -1) &amp;#62;tfind &amp;#62;tdump &amp;#62;end ... Found trace frame 10, tracepoint 1 Data collected at tracepoint 1, trace frame 10: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "BEGIN\000\000\000\000\000\000\002\000\000\000\001\062\000\000\000\001\061\000\001\000\000\000 SELECT indrelid, indkey, generate_subscripts(indkey, 1) idx\n", ' ' &amp;#60;repeats 11 times&amp;#62;, "FROM pg_index\n WHERE indrelid = '\"comments\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... Found trace frame 11, tracepoint 2 Data collected at tracepoint 2, trace frame 11: Found trace frame 12, tracepoint 1 Data collected at tracepoint 1, trace frame 12: $_probe_arg0 = 24523608 *(unsigned char *)$_probe_arg0@512 = "COMMIT\000\000\000\000\000\000\000\000\000\005\000\000\000\021This is a comment\000\000\000\vRead me!\000\000\000\001\062\000\000\000\032\062\060\061\071-11-27 19:49:34.771435\000\000\000\032\062\060\061\071-11-27 19:49:34.771435\000\001\000\000\000ING \"id\"\000\000\005", '\000' &amp;#60;repeats 21 times&amp;#62;, "ents\"'::regclass\n", ' ' &amp;#60;repeats 12 times&amp;#62;, "AND indisprimary\n"... &lt;/pre&gt; &lt;p&gt;Thus, we used SDT markers to extract information about an event in the PostgreSQL process. After we finish observing this PostgreSQL process, use GDB’s &lt;a href="https://sourceware.org/gdb/onlinedocs/gdb/Connecting.html" target="_blank" rel="noopener noreferrer"&gt;&lt;code&gt;monitor exit&lt;/code&gt;&lt;/a&gt; command to stop the &lt;code&gt;gdbserver&lt;/code&gt; process within the container:&lt;/p&gt; &lt;pre&gt;(gdb) detach (gdb) monitor exit (gdb) ^D &lt;/pre&gt; &lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt; &lt;p&gt;The examples in this article illustrate how the current version of &lt;code&gt;oc-inject&lt;/code&gt; increases the options available for debugging containerized applications.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#38;linkname=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F01%2F15%2Finstalling-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject%2F&amp;#038;title=Installing%20debugging%20tools%20into%20a%20Red%20Hat%20OpenShift%20container%20with%20oc-inject" data-a2a-url="https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/" data-a2a-title="Installing debugging tools into a Red Hat OpenShift container with oc-inject"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/"&gt;Installing debugging tools into a Red Hat OpenShift container with oc-inject&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VuD5C7RO2W0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;A previous article, Debugging applications within Red Hat OpenShift containers, gives an overview of tools for debugging applications within Red Hat OpenShift containers, and existing restrictions on their use. One of the restrictions discussed in that article was an inability to install debugging tool packages into an ordinary, unprivileged container once it was already instantiated. [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/"&gt;Installing debugging tools into a Red Hat OpenShift container with oc-inject&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">663407</post-id><dc:creator>Serhei Makarov</dc:creator><dc:date>2020-01-15T08:00:05Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/01/15/installing-debugging-tools-into-a-red-hat-openshift-container-with-oc-inject/</feedburner:origLink></entry></feed>
